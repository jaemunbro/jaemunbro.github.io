# Spark Troublshooting guide
스파크의 문제 사례들과 해결 방법들에 대해 알아보자.
문제 케이스들은 직접 겪은 것들과 본문 하단의 링크의 케이스들을 번역하여 취합했다.

## Out of Memory Exceptions
Spark Job이 Executor 또는 Driver의 out of memory exception으로 인해 실패했을 수 있다.
일반적으로는 Executor의 메모리가 부족한 상황을 많이 만나게 된다. 
Executor의 사이즈를 늘려주는 방법을 통해 해결할 수도 있지만, 근본적으로는 애플리케이션이 얼마나 많은 메모리를 필요로 하는지 이해할 수 있어야 한다. 
이 부분은 스파크 애플리케이션 최적화에 있어서 가장 기본적이고 필수적인 파라미터 부분이므로 반드시 알아두는 것이 좋다.

### Driver Memory Exceptions
#### Exception due to Spark driver running out of memory
드라이버 메모리가 부족한 경우 아래와 같은 형태의 메시지를 볼 수 있다.
```
Exception in thread "broadcast-exchange-0" java.lang.OutOfMemoryError: Not enough memory to build and broadcast the table
to all worker nodes. As a workaround, you can either disable broadcast by setting spark.sql.autoBroadcastJoinThreshold to -1
or increase the spark driver memory by setting spark.driver.memory to a higher value
```
에러 메시지 상 workaround를 제시된대로, 해당 job에 대해서 브로드캐스트 조인을 끄거나, 아니면 드라이버 메모리의 세팅을 늘려줘서 해결할 수 있다. 
아무래도 메모리가 허용한다면 당연히 후자가 좋을 것이다. 
`--conf spark.driver.memory= <XX>g`

#### Job failure because the Application Master that launches the driver exceeds memory limits
Application Master(AM)이 드라이버를 메모리 리밋을 넘겨서 런칭했고 YARN에 의해 terminated된 경우.
```
Diagnostics: Container [pid=<XXXXX>,containerID=container_<XXXXXXXXXX>_<XXXX>_<XX>_<XXXXXX>] is running beyond physical memory limits.
Current usage: <XX> GB of <XX> GB physical memory used; <XX> GB of <XX> GB virtual memory used. Killing container
```

### Executor Memory Exceptions 
#### Exception because executor runs out of memory
스파크 운영 중 종종 마주치게 되는 전형적인 GC issue.
```
Executor task launch worker for task XXXXXX ERROR Executor: Exception in task XX.X in stage X.X (TID XXXXXX)
java.lang.OutOfMemoryError: GC overhead limit exceeded
```
Executor의 사이즈를 늘려주는 방법을 통해 해결한다. 
`--conf spark.executor.memory= <XX>g`
혹은 partition의 개수를 조정하거나, 로드되는 데이터 자체를 조정하는 방향을 고민해볼 수 있다.


#### FetchFailedException due to executor running out of memory
```
ShuffleMapStage XX (sql at SqlWrapper.scala:XX) failed in X.XXX s due to org.apache.spark.shuffle.FetchFailedException:
failed to allocate XXXXX byte(s) of direct memory (used: XXXXX, max: XXXXX)
Copy to clipboard
```
executor 메모리를 더 늘려주거나,
`--conf spark.executor.memory= <XX>g`
shuffle partition의 수를 더 늘려줄 수 있다.
`--spark.sql.shuffle.partitions`

#### Executor container killed by YARN for exceeding memory limits
Executor를 호스닝하는 container가 overhead task나 executor task를 위해서 더 많은 메모리를 필요로 하는 경우 아래와 같은 에러가 발생할 수 있다.
```
org.apache.spark.SparkException: Job aborted due to stage failure: Task X in stage X.X failed X times,
most recent failure: Lost task X.X in stage X.X (TID XX, XX.XX.X.XXX, executor X): ExecutorLostFailure
(executor X exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. XX.X GB
of XX.X GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead
```
executor의 memory overhead 비중을 더 높게 세팅해줄 수 있다.
executor의 메모리 오버헤드 사이즈는 executor의 사이즈에 비례해서 커진다.(대략 6-10%)
best practice는 executor size에 맞춰서 memory overhead size도 조정해주는 것이다.
`--conf spark.executor.memoryOverhead=XXXX`
위의 방법이 통하지 않는다면, 더 큰 인스턴스로 옮기거나, 코어의 개수를 줄여볼 수도 있다.
코어의 개수를 줄이면 메모리가 낭비되겠지만, job은 일단 돌릴 수 있을 것이다.
`--executor-cores=XX`





## Reference
https://docs.qubole.com/en/latest/troubleshooting-guide/spark-ts/troubleshoot-spark.html
https://medium.com/ibm-data-ai/beginners-troubleshooting-guide-for-spark-ibm-analytics-engine-199019cfc6b4
https://www.slideshare.net/jcmia1/a-beginners-guide-on-troubleshooting-spark-applications
