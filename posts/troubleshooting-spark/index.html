<!DOCTYPE html><html lang="en-US" mode="dark" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="Spark - Troubleshooting Cheatsheet (스파크 - 트러블슈팅 가이드)" /><meta name="author" content="Jaemun Jung" /><meta property="og:locale" content="en_US" /><meta name="description" content="스파크의 문제 사례들과 그 해결 방법들에 대해 알아보자. 문제 케이스들은 일부 직접 겪은 것들과 본문 하단 링크의 케이스들을 취합하였다." /><meta property="og:description" content="스파크의 문제 사례들과 그 해결 방법들에 대해 알아보자. 문제 케이스들은 일부 직접 겪은 것들과 본문 하단 링크의 케이스들을 취합하였다." /><link rel="canonical" href="https://jaemunbro.github.io/posts/troubleshooting-spark/" /><meta property="og:url" content="https://jaemunbro.github.io/posts/troubleshooting-spark/" /><meta property="og:site_name" content="Jaemun Jung" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-04-30T01:43:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Spark - Troubleshooting Cheatsheet (스파크 - 트러블슈팅 가이드)" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"Jaemun Jung"},"description":"스파크의 문제 사례들과 그 해결 방법들에 대해 알아보자. 문제 케이스들은 일부 직접 겪은 것들과 본문 하단 링크의 케이스들을 취합하였다.","url":"https://jaemunbro.github.io/posts/troubleshooting-spark/","@type":"BlogPosting","headline":"Spark - Troubleshooting Cheatsheet (스파크 - 트러블슈팅 가이드)","dateModified":"2021-05-06T02:32:50+09:00","datePublished":"2021-04-30T01:43:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://jaemunbro.github.io/posts/troubleshooting-spark/"},"@context":"https://schema.org"}</script><title>Spark - Troubleshooting Cheatsheet (스파크 - 트러블슈팅 가이드) | Jaemun Jung</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-WKRD9Q3FPK"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-WKRD9Q3FPK'); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://media-exp1.licdn.com/dms/image/C5103AQGerVQv-H9XRg/profile-displayphoto-shrink_400_400/0/1586752686385?e=1640217600&v=beta&t=CDknpaAWkjeC1KFgz9zAhkxrhUhAvxCrcjnZJtElD3U" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Jaemun Jung</a></div><div class="site-subtitle font-italic">Data Engineer. Let the data flow!</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/jaemunbro" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['jaemunbro','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://jaemunbro.medium.com/" aria-label="medium" target="_blank" rel="noopener"> <i class="fab fa-medium"></i> </a> <a href="https://www.linkedin.com/in/ryan-jaemun-jung-055350b3/" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Spark - Troubleshooting Cheatsheet (스파크 - 트러블슈팅 가이드)</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Spark - Troubleshooting Cheatsheet (스파크 - 트러블슈팅 가이드)</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Jaemun Jung </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Fri, Apr 30, 2021, 1:43 AM +0900" prep="on" > Apr 30 <i class="unloaded">2021-04-30T01:43:00+09:00</i> </span></div><div> <span> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Thu, May 6, 2021, 2:32 AM +0900" prefix="Updated " > May 6 <i class="unloaded">2021-05-06T02:32:50+09:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3180 words">17 min</span></div></div><div class="post-content"><p>스파크의 문제 사례들과 그 해결 방법들에 대해 알아보자.<br /> 문제 케이스들은 일부 직접 겪은 것들과 본문 하단 링크의 케이스들을 취합하였다.</p><h1 id="troubleshooting-tips">Troubleshooting Tips</h1><h3 id="트러블슈팅을-위해-verbose-mode를-활용하자">트러블슈팅을 위해 verbose mode를 활용하자</h3><hr /><p><code class="language-plaintext highlighter-rouge">spark-submit --driver-memory 10g --verbose --master yarn --executor memory...</code><br /> 다음 정보들이 프린트된다.</p><ul><li>all default properties<li>command line options<li>setting from spark ‘conf’ file<li>setting from CLI</ul><h3 id="executor-thread--heap-dump">executor thread &amp; heap dump</h3><hr /><p><code class="language-plaintext highlighter-rouge">jmap, jstack, jstat, jhat</code>과 같은 OpenJDK 툴을 통해 executor의 thread dump나 heap dump를 떠볼 수 있다. YARN 컨테이너의 pid를 찾아서 사용한다.</p><ul><li>for full thread dump<div class="language-bash highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>jstack <span class="nt">-l</span> 355583 <span class="o">&gt;</span> javacore.355583
</pre></table></code></div></div><li>for full heap dump<div class="language-bash highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>jmap <span class="nt">-dump</span>:live,format<span class="o">=</span>b,file<span class="o">=</span>heapdump.355583 355583 
</pre></table></code></div></div></ul><h1 id="error-cases">Error Cases</h1><hr /><h3 id="compiled-ok-but-run-time-noclassdeffounderror">Compiled OK, but run-time NoClassDefFoundError</h3><div class="language-java highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nl">NoClassDefFoundError:</span> <span class="nc">Exception</span> <span class="n">in</span> <span class="n">thread</span> <span class="s">"main"</span> <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">NoClassDefFoundError</span><span class="o">:</span> <span class="n">org</span><span class="o">/</span><span class="n">apache</span><span class="o">/</span><span class="n">kafka</span><span class="o">/</span><span class="n">clients</span><span class="o">/</span><span class="n">producer</span><span class="o">/</span><span class="nc">KafkaProducer</span> <span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">Class</span><span class="o">.</span><span class="na">getDeclaredMethods0</span><span class="o">(</span><span class="nc">Native</span> <span class="nc">Method</span><span class="o">)</span> <span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">Class</span><span class="o">.</span><span class="na">privateGetDeclaredMethods</span><span class="o">(</span><span class="nc">Class</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">2701</span><span class="o">)</span> <span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">Class</span><span class="o">.</span><span class="na">privateGetMethodRecursive</span><span class="o">(</span><span class="nc">Class</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">3048</span><span class="o">)</span> <span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">Class</span><span class="o">.</span><span class="na">getMethod0</span><span class="o">(</span><span class="nc">Class</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">3018</span><span class="o">)</span>
</pre></table></code></div></div><p><code class="language-plaintext highlighter-rouge">--packages</code> 를 통해 Maven Jar 포함 e.g.)</p><div class="language-java highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">spark</span><span class="o">-</span><span class="n">submit</span> <span class="o">--</span><span class="n">driver</span><span class="o">-</span><span class="n">memory</span> <span class="mi">12</span><span class="n">g</span> <span class="o">--</span><span class="n">verbose</span> <span class="o">--</span><span class="n">master</span> <span class="n">yarn</span><span class="o">-</span><span class="n">client</span> <span class="o">--</span><span class="n">executor</span><span class="o">-</span><span class="n">memory</span> <span class="mi">4096</span><span class="n">m</span> <span class="o">--</span><span class="n">num</span><span class="o">-</span><span class="n">executors</span> <span class="mi">20</span>  <span class="o">--</span><span class="n">packages</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">:</span><span class="n">spark</span><span class="o">-</span><span class="n">streaming</span><span class="o">-</span><span class="n">kafka_2</span><span class="o">.</span><span class="mi">10</span><span class="o">:</span><span class="mf">1.5</span><span class="o">.</span><span class="mi">1</span>
</pre></table></code></div></div><ul><li>repo look up 순서<ol><li>local Maven repo - local machine<li>Maven centoral - Web<li>Additional remote repositories specified in - repositories</ol></ul><h3 id="no-space-left-on-device">No space left on device</h3><hr /><div class="language-java highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">stage</span> <span class="mf">89.3</span> <span class="n">failed</span> <span class="mi">4</span> <span class="n">times</span><span class="o">,</span> <span class="n">most</span> <span class="n">recent</span> <span class="nl">failure:</span> <span class="nc">Lost</span> <span class="n">task</span> <span class="mf">38.4</span> <span class="n">in</span> <span class="n">stage</span> <span class="mf">89.3</span> <span class="o">(</span><span class="no">TID</span> <span class="mi">30100</span><span class="o">,</span> <span class="n">rhel4</span><span class="o">.</span><span class="na">cisco</span><span class="o">.</span><span class="na">com</span><span class="o">):</span> <span class="n">java</span><span class="o">.</span><span class="na">io</span><span class="o">.</span><span class="na">IOException</span><span class="o">:</span> <span class="nc">No</span> <span class="n">space</span> <span class="n">left</span> <span class="n">on</span> <span class="n">device</span> <span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">io</span><span class="o">.</span><span class="na">FileOutputStream</span><span class="o">.</span><span class="na">writeBytes</span><span class="o">(</span><span class="nc">Native</span> <span class="nc">Method</span><span class="o">)</span> <span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">io</span><span class="o">.</span><span class="na">FileOutputStream</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="nc">FileOutputStream</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">326</span><span class="o">)</span> <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">storage</span><span class="o">.</span><span class="na">TimeTrackingOutputStream</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="nc">TimeTrackingOutputStream</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">58</span><span class="o">)</span> <span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">io</span><span class="o">.</span><span class="na">BufferedOutputStream</span><span class="o">.</span><span class="na">flushBuffer</span><span class="o">(</span><span class="nc">BufferedOutputStream</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">82</span><span class="o">)</span> <span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">io</span><span class="o">.</span><span class="na">BufferedOutputStream</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="nc">BufferedOutputStream</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">126</span><span class="o">)</span>
</pre></table></code></div></div><p>얼마전 운영중인 클러스터에서 발생했던 에러다.<br /> 스파크가 map output file들과 RDD를 저장해두는 <code class="language-plaintext highlighter-rouge">/tmp</code>가 꽉찬 경우다. 일단은 cron에 정기적으로 tmp 정리를 통해 해결했다.</p><ul><li><code class="language-plaintext highlighter-rouge">spark.local.dir</code> 파라미터값의 디폴트값이 <code class="language-plaintext highlighter-rouge">/tmp</code>인데, 근본적으로 <code class="language-plaintext highlighter-rouge">/tmp</code>를 Spark의 scratch 공간으로 두는 것 자체가 적절치 않다. 아래 두가지 이유 때문인데<ol><li><code class="language-plaintext highlighter-rouge">/tmp</code>는 일반적으로 작은 공간이 할당되며 OS를 위한 공간이다.<li><code class="language-plaintext highlighter-rouge">/tmp</code>는 보통 single disk로 IO bottleneck의 원인이 될 수 있다.</ol><li><code class="language-plaintext highlighter-rouge">spark-defualts.conf</code>에 아래와 같은 내용을 추가하자.<br /> <code class="language-plaintext highlighter-rouge">spark.local.dir /data/disk1/tmp,/data/disk2/tmp,/data/disk3/tmp,/data/disk4/tmp,...</code></ul><h3 id="brodcasttimeout-error">BrodcastTimeout Error</h3><hr /><p>역시 최근 클러스터에서 발생했는데, 명확하게 BroadcastTimeout Error라고 떨어지는 경우도 있지만, surface상에는 Catalyst error로 떨어지는 경우도 있는 것 같다.</p><div class="language-java highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre> <span class="nc">Typical</span> <span class="n">error</span> <span class="n">stream7</span><span class="o">/</span><span class="n">query_07_24_48</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">out</span><span class="o">:</span><span class="nl">Error:</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">catalyst</span><span class="o">.</span><span class="na">errors</span><span class="o">.</span><span class="na">package</span><span class="n">$TreeNodeException</span><span class="o">:</span> <span class="n">execute</span><span class="o">,</span> <span class="nl">tree:</span> <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">execution</span><span class="o">.</span><span class="na">exchange</span><span class="o">.</span><span class="na">ShuffleExchange</span><span class="err">$</span><span class="n">$anonfun$doExecute</span> <span class="err">$</span><span class="mi">1</span><span class="o">.</span><span class="na">apply</span><span class="o">(</span><span class="nc">ShuffleExchange</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">122</span><span class="o">)</span> <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">execution</span><span class="o">.</span><span class="na">exchange</span><span class="o">.</span><span class="na">ShuffleExchange</span><span class="err">$</span><span class="n">$anonfun$doExecute</span> <span class="err">$</span><span class="mi">1</span><span class="o">.</span><span class="na">apply</span><span class="o">(</span><span class="nc">ShuffleExchange</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">113</span><span class="o">)</span> <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">catalyst</span><span class="o">.</span><span class="na">errors</span><span class="o">.</span><span class="na">package</span><span class="err">$</span><span class="o">.</span><span class="na">attachTree</span><span class="o">(</span><span class="kn">package</span><span class="nn">.scala</span><span class="o">:</span><span class="mi">49</span><span class="o">)</span> <span class="o">...</span> <span class="mi">96</span> <span class="n">more</span> <span class="nc">Caused</span> <span class="nl">by:</span> <span class="n">java</span><span class="o">.</span><span class="na">util</span><span class="o">.</span><span class="na">concurrent</span><span class="o">.</span><span class="na">TimeoutException</span><span class="o">:</span> <span class="nc">Futures</span> <span class="n">timed</span> <span class="n">out</span> <span class="n">after</span> <span class="o">[</span><span class="mi">800</span> <span class="n">seconds</span><span class="o">]</span> <span class="n">at</span> <span class="n">scala</span><span class="o">.</span><span class="na">concurrent</span><span class="o">.</span><span class="na">impl</span><span class="o">.</span><span class="na">Promise</span><span class="n">$DefaultPromise</span><span class="o">.</span><span class="na">ready</span><span class="o">(</span><span class="nc">Promise</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">219</span><span class="o">)</span> <span class="n">at</span> <span class="n">scala</span><span class="o">.</span><span class="na">concurrent</span><span class="o">.</span><span class="na">impl</span><span class="o">.</span><span class="na">Promise</span><span class="n">$DefaultPromise</span><span class="o">.</span><span class="na">result</span><span class="o">(</span><span class="nc">Promise</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">223</span><span class="o">)</span> <span class="n">at</span> <span class="n">scala</span><span class="o">.</span><span class="na">concurrent</span><span class="o">.</span><span class="na">Await</span><span class="err">$</span><span class="n">$anonfun$result</span><span class="err">$</span><span class="mi">1</span><span class="o">.</span><span class="na">apply</span><span class="o">(</span><span class="kn">package</span><span class="nn">.scala</span><span class="o">:</span><span class="mi">190</span><span class="o">)</span> <span class="n">at</span> <span class="n">scala</span><span class="o">.</span><span class="na">concurrent</span><span class="o">.</span><span class="na">BlockContext</span><span class="n">$DefaultBlockContext</span><span class="err">$</span><span class="o">.</span><span class="na">blockOn</span><span class="o">(</span><span class="nc">BlockContext</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">53</span><span class="o">)</span> <span class="n">at</span> <span class="n">scala</span><span class="o">.</span><span class="na">concurrent</span><span class="o">.</span><span class="na">Await</span><span class="err">$</span><span class="o">.</span><span class="na">result</span><span class="o">(</span><span class="kn">package</span><span class="nn">.scala</span><span class="o">:</span><span class="mi">190</span><span class="o">)</span> <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">util</span><span class="o">.</span><span class="na">ThreadUtils</span><span class="err">$</span><span class="o">.</span><span class="na">awaitResult</span><span class="o">(</span><span class="nc">ThreadUtils</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">190</span><span class="o">)</span> <span class="o">...</span> <span class="mi">208</span> <span class="n">more</span> <span class="err">§ </span> <span class="nc">On</span> <span class="n">surface</span> <span class="n">appears</span> <span class="n">to</span> <span class="n">be</span> <span class="nc">Catalyst</span> <span class="nf">error</span> <span class="o">(</span><span class="n">optimizer</span><span class="o">)</span> 
</pre></table></code></div></div><p><code class="language-plaintext highlighter-rouge">spark.sql.broadcastTimeout 1200</code> 처럼 parameter를 늘려주는 설정을 통해 해결한다. broadcast하는 size의 limit이 있으므로, 무제한으로 broadcast 되지는 않을 것이라 보았다. 클러스터에서 수행되는 긴 쿼리 기준으로 세팅할 수 있을 것이다.</p><h2 id="out-of-memory-exceptions">Out of Memory Exceptions</h2><hr /><p>Spark Job이 Executor 또는 Driver의 out of memory exception으로 인해 실패했을 수 있다. 일반적으로는 Executor의 메모리가 부족한 상황을 많이 만나게 된다. Executor의 사이즈를 늘려주는 방법을 통해 해결할 수도 있지만, 근본적으로는 애플리케이션이 얼마나 많은 메모리를 필요로 하는지 이해할 수 있어야 한다. 이 부분은 스파크 애플리케이션 최적화에 있어서 가장 기본적이고 필수적인 파라미터 부분이므로 반드시 알아두는 것이 좋다.<br /> 아래 부터 Driver와 Executor의 메모리 에러 상황들에 대해서 더 알아보자.</p><h2 id="driver-memory-exceptions">Driver Memory Exceptions</h2><hr /><p>드라이버 메모리가 부족한 경우는 보통 (휴먼 에러가 아니라면) <code class="language-plaintext highlighter-rouge">--driver-memory</code> 설정을 통해 해결한다. Default값인 512M는 일반적으로 운영환경에서는 너무 작은 값이다.<br /> <strong>Spark SQL과 Spark Strmeaing은 일반적으로 큰 driver heap size를 요구하는 spark job의 형태</strong>다.</p><h3 id="exception-due-to-spark-driver-running-out-of-memory">Exception due to Spark driver running out of memory</h3><hr /><p>명시적으로 collect() action 등의 driver memory를 사용하지 않는데, driver memory exception이 나서 의아했던 적이 있다. Spark SQL의 Optimizer가 relation을 broadcasting 하기 위해서 중간 과정으로 필요할 수 있다. 드라이버 메모리가 부족한 경우 아래와 같은 형태의 메시지를 볼 수 있다.</p><div class="language-java highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="nc">Exception</span> <span class="n">in</span> <span class="n">thread</span> <span class="s">"broadcast-exchange-0"</span> <span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">OutOfMemoryError</span><span class="o">:</span> <span class="nc">Not</span> <span class="n">enough</span> <span class="n">memory</span> <span class="n">to</span> <span class="n">build</span> <span class="n">and</span> <span class="n">broadcast</span> <span class="n">the</span> <span class="n">table</span>
<span class="n">to</span> <span class="n">all</span> <span class="n">worker</span> <span class="n">nodes</span><span class="o">.</span> <span class="nc">As</span> <span class="n">a</span> <span class="n">workaround</span><span class="o">,</span> <span class="n">you</span> <span class="n">can</span> <span class="n">either</span> <span class="n">disable</span> <span class="n">broadcast</span> <span class="n">by</span> <span class="n">setting</span> <span class="n">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">autoBroadcastJoinThreshold</span> <span class="n">to</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">or</span> <span class="n">increase</span> <span class="n">the</span> <span class="n">spark</span> <span class="n">driver</span> <span class="n">memory</span> <span class="n">by</span> <span class="n">setting</span> <span class="n">spark</span><span class="o">.</span><span class="na">driver</span><span class="o">.</span><span class="na">memory</span> <span class="n">to</span> <span class="n">a</span> <span class="n">higher</span> <span class="n">value</span>
</pre></table></code></div></div><p>에러 메시지 상 workaround를 제시된대로, 해당 job에 대해서 브로드캐스트 조인을 끄거나, 브로드캐스트 조인의 threshold를 낮추는 것을 고려할 수도 있다. 아니면 드라이버 메모리의 세팅을 늘려줘서 해결할 수 있다. 메모리가 허용한다면 당연히 후자가 좋을 것이다. <code class="language-plaintext highlighter-rouge">--conf spark.driver.memory= &lt;XX&gt;g</code></p><h3 id="job-failure-because-the-application-master-that-launches-the-driver-exceeds-memory-limits">Job failure because the Application Master that launches the driver exceeds memory limits</h3><hr /><p>Application Master(AM)이 드라이버를 메모리 리밋을 넘겨서 런칭했고 YARN에 의해 terminated된 경우.</p><div class="language-java highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="nl">Diagnostics:</span> <span class="nc">Container</span> <span class="o">[</span><span class="n">pid</span><span class="o">=&lt;</span><span class="no">XXXXX</span><span class="o">&gt;,</span><span class="n">containerID</span><span class="o">=</span><span class="n">container_</span><span class="o">&lt;</span><span class="no">XXXXXXXXXX</span><span class="o">&gt;</span><span class="n">_</span><span class="o">&lt;</span><span class="no">XXXX</span><span class="o">&gt;</span><span class="n">_</span><span class="o">&lt;</span><span class="no">XX</span><span class="o">&gt;</span><span class="n">_</span><span class="o">&lt;</span><span class="no">XXXXXX</span><span class="o">&gt;]</span> <span class="n">is</span> <span class="n">running</span> <span class="n">beyond</span> <span class="n">physical</span> <span class="n">memory</span> <span class="n">limits</span><span class="o">.</span>
<span class="nc">Current</span> <span class="nl">usage:</span> <span class="o">&lt;</span><span class="no">XX</span><span class="o">&gt;</span> <span class="no">GB</span> <span class="n">of</span> <span class="o">&lt;</span><span class="no">XX</span><span class="o">&gt;</span> <span class="no">GB</span> <span class="n">physical</span> <span class="n">memory</span> <span class="n">used</span><span class="o">;</span> <span class="o">&lt;</span><span class="no">XX</span><span class="o">&gt;</span> <span class="no">GB</span> <span class="n">of</span> <span class="o">&lt;</span><span class="no">XX</span><span class="o">&gt;</span> <span class="no">GB</span> <span class="n">virtual</span> <span class="n">memory</span> <span class="n">used</span><span class="o">.</span> <span class="nc">Killing</span> <span class="n">container</span>
</pre></table></code></div></div><h2 id="executor-memory-exceptions">Executor Memory Exceptions</h2><h3 id="exception-because-executor-runs-out-of-memory">Exception because executor runs out of memory</h3><hr /><p>스파크 운영 중 종종 마주치게 되는 전형적인 GC issue.</p><ul><li>garbage collection에 98% 이상의 total time이 쓰여지고 있는 경우<li>gc를 통해 2% 이하의 heap이 회복된 경우<li>top command를 통해 확인했을 때, 1 cpu core가 100% 사용률을 치고 있는데 완료되고 있는 job은 없는 경우<div class="language-java highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="nc">Executor</span> <span class="n">task</span> <span class="n">launch</span> <span class="n">worker</span> <span class="k">for</span> <span class="n">task</span> <span class="no">XXXXXX</span> <span class="no">ERROR</span> <span class="nl">Executor:</span> <span class="nc">Exception</span> <span class="n">in</span> <span class="n">task</span> <span class="no">XX</span><span class="o">.</span><span class="na">X</span> <span class="n">in</span> <span class="n">stage</span> <span class="no">X</span><span class="o">.</span><span class="na">X</span> <span class="o">(</span><span class="no">TID</span> <span class="no">XXXXXX</span><span class="o">)</span>
<span class="n">java</span><span class="o">.</span><span class="na">lang</span><span class="o">.</span><span class="na">OutOfMemoryError</span><span class="o">:</span> <span class="no">GC</span> <span class="n">overhead</span> <span class="n">limit</span> <span class="n">exceeded</span>
</pre></table></code></div></div></ul><ol><li><p>Executor의 사이즈를 늘려주는 방법을 통해 해결한다.<br /> <code class="language-plaintext highlighter-rouge">--conf spark.executor.memory= &lt;XX&gt;g</code></p><li><p>GC policy를 변경한다.</p><ul><li>Spark default는 -XX:UseParallelGC<li>-XX:G1GC 로 overwrite을 시도해볼 수 있다.<li>Default가 일반적으로 좋지만, 상황에 따라 다를 수 있다. (자세한 내용은 별도의 포스트에서 다루고자 한다)</ul></ol><h3 id="fetchfailedexception-due-to-executor-running-out-of-memory">FetchFailedException due to executor running out of memory</h3><hr /><div class="language-java highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="nc">ShuffleMapStage</span> <span class="nf">XX</span> <span class="o">(</span><span class="n">sql</span> <span class="n">at</span> <span class="nc">SqlWrapper</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="no">XX</span><span class="o">)</span> <span class="n">failed</span> <span class="n">in</span> <span class="no">X</span><span class="o">.</span><span class="na">XXX</span> <span class="n">s</span> <span class="n">due</span> <span class="n">to</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">shuffle</span><span class="o">.</span><span class="na">FetchFailedException</span><span class="o">:</span>
<span class="n">failed</span> <span class="n">to</span> <span class="n">allocate</span> <span class="no">XXXXX</span> <span class="nf">byte</span><span class="o">(</span><span class="n">s</span><span class="o">)</span> <span class="n">of</span> <span class="n">direct</span> <span class="nf">memory</span> <span class="o">(</span><span class="nl">used:</span> <span class="no">XXXXX</span><span class="o">,</span> <span class="nl">max:</span> <span class="no">XXXXX</span><span class="o">)</span>
<span class="nc">Copy</span> <span class="n">to</span> <span class="n">clipboard</span>
</pre></table></code></div></div><p>executor 메모리를 더 늘려주거나, <code class="language-plaintext highlighter-rouge">--conf spark.executor.memory= &lt;XX&gt;g</code> shuffle partition의 수를 더 늘려줄 수 있다. <code class="language-plaintext highlighter-rouge">--spark.sql.shuffle.partitions</code></p><h3 id="executor-container-killed-by-yarn-for-exceeding-memory-limits">Executor container killed by YARN for exceeding memory limits</h3><hr /><p>Executor를 호스닝하는 container가 overhead task나 executor task를 위해서 더 많은 메모리를 필요로 하는 경우 아래와 같은 에러가 발생할 수 있다.</p><div class="language-java highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">SparkException</span><span class="o">:</span> <span class="nc">Job</span> <span class="n">aborted</span> <span class="n">due</span> <span class="n">to</span> <span class="n">stage</span> <span class="nl">failure:</span> <span class="nc">Task</span> <span class="no">X</span> <span class="n">in</span> <span class="n">stage</span> <span class="no">X</span><span class="o">.</span><span class="na">X</span> <span class="n">failed</span> <span class="no">X</span> <span class="n">times</span><span class="o">,</span>
<span class="n">most</span> <span class="n">recent</span> <span class="nl">failure:</span> <span class="nc">Lost</span> <span class="n">task</span> <span class="no">X</span><span class="o">.</span><span class="na">X</span> <span class="n">in</span> <span class="n">stage</span> <span class="no">X</span><span class="o">.</span><span class="na">X</span> <span class="o">(</span><span class="no">TID</span> <span class="no">XX</span><span class="o">,</span> <span class="no">XX</span><span class="o">.</span><span class="na">XX</span><span class="o">.</span><span class="na">X</span><span class="o">.</span><span class="na">XXX</span><span class="o">,</span> <span class="n">executor</span> <span class="no">X</span><span class="o">):</span> <span class="nc">ExecutorLostFailure</span>
<span class="o">(</span><span class="n">executor</span> <span class="no">X</span> <span class="n">exited</span> <span class="n">caused</span> <span class="n">by</span> <span class="n">one</span> <span class="n">of</span> <span class="n">the</span> <span class="n">running</span> <span class="n">tasks</span><span class="o">)</span> <span class="nl">Reason:</span> <span class="nc">Container</span> <span class="n">killed</span> <span class="n">by</span> <span class="no">YARN</span> <span class="k">for</span> <span class="n">exceeding</span> <span class="n">memory</span> <span class="n">limits</span><span class="o">.</span> <span class="no">XX</span><span class="o">.</span><span class="na">X</span> <span class="no">GB</span>
<span class="n">of</span> <span class="no">XX</span><span class="o">.</span><span class="na">X</span> <span class="no">GB</span> <span class="n">physical</span> <span class="n">memory</span> <span class="n">used</span><span class="o">.</span> <span class="nc">Consider</span> <span class="n">boosting</span> <span class="n">spark</span><span class="o">.</span><span class="na">yarn</span><span class="o">.</span><span class="na">executor</span><span class="o">.</span><span class="na">memoryOverhead</span>
</pre></table></code></div></div><p>executor의 memory overhead 비중을 더 높게 세팅해줄 수 있다. executor의 메모리 오버헤드 사이즈는 executor의 사이즈에 비례해서 커진다.(대략 6-10%) best practice는 executor size에 맞춰서 memory overhead size도 조정해주는 것이다.<br /> <code class="language-plaintext highlighter-rouge">--conf spark.executor.memoryOverhead=XXXX</code><br /> 위의 방법이 통하지 않는다면, 더 큰 인스턴스로 옮기거나, 코어의 개수를 줄여볼 수도 있다.<br /> 코어의 개수를 줄이면 메모리가 낭비되겠지만, job은 일단 돌릴 수 있을 것이다.<br /> <code class="language-plaintext highlighter-rouge">--executor-cores=XX</code></p><h3 id="filealreadyexistsexception">FileAlreadyExistsException</h3><hr /><p>이전에 실패한 task에서 파일들을 남겨서 FileAlreadyExistsException를 발생시킬 수 있다. executor가 메모리 부족으로 실패하고 다른 executor가 다시 해당 task를 이어받았을 때 발생할 수 있다. 어떤 Spark executor가 실패했을 때, Maximum number만큼 retry하고 나서 이 Exception을 남길 수 있다.</p><div class="language-java highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">SparkException</span><span class="o">:</span> <span class="nc">Task</span> <span class="n">failed</span> <span class="k">while</span> <span class="n">writing</span> <span class="n">rows</span>
<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">execution</span><span class="o">.</span><span class="na">datasources</span><span class="o">.</span><span class="na">FileFormatWriter</span><span class="err">$</span><span class="o">.</span><span class="na">org</span><span class="n">$apache$spark$sql$execution$datasources$FileFormatWriter</span><span class="err">$</span><span class="n">$executeTask</span><span class="o">(</span><span class="nc">FileFormatWriter</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">272</span><span class="o">)</span>
<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">execution</span><span class="o">.</span><span class="na">datasources</span><span class="o">.</span><span class="na">FileFormatWriter</span><span class="err">$</span><span class="n">$anonfun$write</span><span class="err">$</span><span class="mi">1</span><span class="err">$</span><span class="n">$anonfun$apply$mcV$sp</span><span class="err">$</span><span class="mi">1</span><span class="o">.</span><span class="na">apply</span><span class="o">(</span><span class="nc">FileFormatWriter</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">191</span><span class="o">)</span>
<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">execution</span><span class="o">.</span><span class="na">datasources</span><span class="o">.</span><span class="na">FileFormatWriter</span><span class="err">$</span><span class="n">$anonfun$write</span><span class="err">$</span><span class="mi">1</span><span class="err">$</span><span class="n">$anonfun$apply$mcV$sp</span><span class="err">$</span><span class="mi">1</span><span class="o">.</span><span class="na">apply</span><span class="o">(</span><span class="nc">FileFormatWriter</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">190</span><span class="o">)</span>
<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">scheduler</span><span class="o">.</span><span class="na">ResultTask</span><span class="o">.</span><span class="na">runTask</span><span class="o">(</span><span class="nc">ResultTask</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">87</span><span class="o">)</span>
<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">scheduler</span><span class="o">.</span><span class="na">Task</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="nc">Task</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">108</span><span class="o">)</span>
<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">executor</span><span class="o">.</span><span class="na">Executor</span><span class="n">$TaskRunner</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="nc">Executor</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">335</span><span class="o">)</span>
<span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">util</span><span class="o">.</span><span class="na">concurrent</span><span class="o">.</span><span class="na">ThreadPoolExecutor</span><span class="o">.</span><span class="na">runWorker</span><span class="o">(</span><span class="nc">ThreadPoolExecutor</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">1142</span><span class="o">)</span>
<span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="na">util</span><span class="o">.</span><span class="na">concurrent</span><span class="o">.</span><span class="na">ThreadPoolExecutor</span><span class="n">$Worker</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="nc">ThreadPoolExecutor</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">617</span><span class="o">)</span>
<span class="o">...</span> <span class="mi">1</span> <span class="n">more</span>
<span class="nc">Caused</span> <span class="nl">by:</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">fs</span><span class="o">.</span><span class="na">FileAlreadyExistsException</span><span class="o">:</span> <span class="nl">s3:</span><span class="c1">//xxxxxx/xxxxxxx/xxxxxx/analysis-results/datasets/model=361/dataset=encoded_unified/dataset_version=vvvvv.snappy.parquet already exists</span>
<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">fs</span><span class="o">.</span><span class="na">s3a</span><span class="o">.</span><span class="na">S3AFileSystem</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="nc">S3AFileSystem</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">806</span><span class="o">)</span>
<span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">fs</span><span class="o">.</span><span class="na">FileSystem</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="nc">FileSystem</span><span class="o">.</span><span class="na">java</span><span class="o">:</span><span class="mi">914</span><span class="o">)</span>
</pre></table></code></div></div><ul><li>FileAlreadyExistsException의 root cause인, 가장 앞서 실패한 original executor의 실패 원인을 밝힌다.</ul><h3 id="max-result-size-exceeded">Max result size exceeded</h3><hr /><div class="language-java highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre> <span class="nc">Typical</span> <span class="n">error</span> <span class="n">stream5</span><span class="o">/</span><span class="n">query_05_22_77</span><span class="o">.</span><span class="na">sql</span><span class="o">.</span><span class="na">out</span><span class="o">:</span><span class="nl">Error:</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">SparkException</span><span class="o">:</span> <span class="nc">Job</span> <span class="n">aborted</span> <span class="n">due</span> <span class="n">to</span> <span class="n">stage</span> <span class="nl">failure:</span> <span class="nc">Total</span> <span class="n">size</span> <span class="n">of</span> <span class="n">serialized</span> <span class="n">results</span> <span class="n">of</span> <span class="mi">381610</span> <span class="n">tasks</span> <span class="o">(</span><span class="mf">5.0</span> <span class="no">GB</span><span class="o">)</span> <span class="n">is</span> <span class="n">bigger</span> <span class="n">than</span> <span class="n">spark</span><span class="o">.</span><span class="na">driver</span><span class="o">.</span><span class="na">maxResultSize</span> <span class="o">(</span><span class="mf">5.0</span> <span class="no">GB</span><span class="o">)</span> <span class="o">(</span><span class="n">state</span><span class="o">=,</span><span class="n">code</span><span class="o">=</span><span class="mi">0</span><span class="o">))</span> <span class="err">§ </span> <span class="nc">Likely</span> <span class="n">to</span> <span class="n">occur</span> <span class="n">with</span> <span class="n">complex</span> <span class="no">SQL</span> <span class="n">on</span> <span class="n">large</span> <span class="n">data</span> <span class="n">volumes</span>
</pre></table></code></div></div><p>큰 데이터 볼륨을 처리하기 위한 복잡한 SQL에서 발생할 가능성이 있다.<br /> Spark Driver Max Result Size값보다 return된 result가 클 때 발생한다.<br /> <code class="language-plaintext highlighter-rouge">--conf spark.driver.maxResultSize</code> 재설정을 통해 해결한다.</p><h3 id="too-large-frame-error">Too Large Frame error</h3><hr /><p>shuffle data size block의 size가 스파크가 처리 할 수 있는 한계인 2GB보다 큰 경우 발생.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>org.apache.spark.shuffle.FetchFailedException: Too large frame: XXXXXXXXXX
at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)

Caused by: java.lang.IllegalArgumentException: Too large frame: XXXXXXXXXX
at org.spark_project.guava.base.Preconditions.checkArgument(Preconditions.java:119)
at org.apache.spark.network.util.TransportFrameDecoder.decodeNext(TransportFrameDecoder.java:133)
</pre></table></code></div></div><ol><li><p><code class="language-plaintext highlighter-rouge">spark.sql.shuffle.partitions</code>의 value를 default 200에서 큰 값으로 조정 -&gt; <code class="language-plaintext highlighter-rouge">spark.default.parallelism</code> 을 <code class="language-plaintext highlighter-rouge">spark.sql.shuffle.partitions</code>과 동일한 값으로 변경</p><li><p>issue가 발생하는 dataframe을 밝혀내보자. dataframe 생성 뒤에 action(어떤 action이든, count 등)을 붙여서 dataframe별로 action을 시켜보고, 문제가 생기는 데이터프레임을 밝혀내볼 수 있다. 해당 데이터프레임을 repartition하고 cache해놓는다. 이 때 파티션이 된 데이터의 skewness가 심하다면 코드의 튜닝이 필요할 수 있다.</p></ol><h3 id="network-timeout">Network Timeout</h3><hr /><div class="language-java highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="mi">16</span><span class="o">/</span><span class="mo">07</span><span class="o">/</span><span class="mi">09</span> <span class="mo">01</span><span class="o">:</span><span class="mi">14</span><span class="o">:</span><span class="mi">18</span> <span class="no">ERROR</span> <span class="n">spark</span><span class="o">.</span><span class="na">ContextCleaner</span><span class="o">:</span> <span class="nc">Error</span> <span class="n">cleaning</span> <span class="n">broadcast</span> <span class="mi">28267</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">rpc</span><span class="o">.</span><span class="na">RpcTimeoutException</span><span class="o">:</span> <span class="nc">Futures</span> <span class="n">timed</span> <span class="n">out</span> <span class="n">after</span> <span class="o">[</span><span class="mi">800</span> <span class="n">seconds</span><span class="o">].</span> <span class="nc">This</span> <span class="n">timeout</span> <span class="n">is</span> <span class="n">controlled</span> <span class="n">by</span> <span class="n">spark</span><span class="o">.</span><span class="na">rpc</span><span class="o">.</span><span class="na">askTimeout</span> <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">rpc</span><span class="o">.</span><span class="na">RpcTimeout</span><span class="o">.</span><span class="na">org</span><span class="n">$apache$spark$rpc$RpcTimeout</span><span class="err">$</span> <span class="n">$createRpcTimeoutException</span><span class="o">(</span><span class="nc">RpcTimeout</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">48</span><span class="o">)</span> <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">rpc</span><span class="o">.</span><span class="na">RpcTimeout</span><span class="err">$</span><span class="n">$anonfun$addMessageIfTimeout</span><span class="err">$</span><span class="mi">1</span><span class="o">.</span><span class="na">applyOrElse</span><span class="o">(</span><span class="nc">RpcTimeout</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">63</span><span class="o">)</span> <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">rpc</span><span class="o">.</span><span class="na">RpcTimeout</span><span class="err">$</span><span class="n">$anonfun$addMessageIfTimeout</span><span class="err">$</span><span class="mi">1</span><span class="o">.</span><span class="na">applyOrElse</span><span class="o">(</span><span class="nc">RpcTimeout</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">59</span><span class="o">)</span> <span class="n">at</span> <span class="n">scala</span><span class="o">.</span><span class="na">PartialFunction</span><span class="n">$OrElse</span><span class="o">.</span><span class="na">apply</span><span class="o">(</span><span class="nc">PartialFunction</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">167</span><span class="o">)</span> <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">rpc</span><span class="o">.</span><span class="na">RpcTimeout</span><span class="o">.</span><span class="na">awaitResult</span><span class="o">(</span><span class="nc">RpcTimeout</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">83</span><span class="o">)</span> <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">storage</span><span class="o">.</span><span class="na">BlockManagerMaster</span><span class="o">.</span><span class="na">removeBroadcast</span><span class="o">(</span><span class="nc">BlockManagerMaster</span><span class="o">.</span><span class="na">scala</span><span class="o">:</span><span class="mi">143</span><span class="o">)</span> <span class="nc">And</span> <span class="n">timeout</span> <span class="n">exceptions</span> <span class="n">related</span> <span class="n">to</span> <span class="n">the</span> <span class="nl">following:</span> <span class="n">spark</span><span class="o">.</span><span class="na">core</span><span class="o">.</span><span class="na">connection</span><span class="o">.</span><span class="na">ack</span><span class="o">.</span><span class="na">wait</span><span class="o">.</span><span class="na">timeout</span> <span class="n">spark</span><span class="o">.</span><span class="na">akka</span><span class="o">.</span><span class="na">timeout</span> <span class="n">spark</span><span class="o">.</span><span class="na">storage</span><span class="o">.</span><span class="na">blockManagerSlaveTimeoutMs</span> <span class="n">spark</span><span class="o">.</span><span class="na">shuffle</span><span class="o">.</span><span class="na">io</span><span class="o">.</span><span class="na">connectionTimeout</span> <span class="n">spark</span><span class="o">.</span><span class="na">rpc</span><span class="o">.</span><span class="na">askTimeout</span> <span class="n">spark</span><span class="o">.</span><span class="na">rpc</span><span class="o">.</span><span class="na">lookupTimeout</span>
</pre></table></code></div></div><p>시스템 리소스 상황에 따라 발생할 수 있다. 시스템 리소스의 튜닝이 최우선이고, 안전장치로 timeout setting을 늘려줄 수 있다.<br /> <code class="language-plaintext highlighter-rouge">spark.network.timeout</code> 파라미터를 늘려준다. default는 120이다. 에러가 발생한 timeout 시간만큼 늘려줘 본다.</p><h3 id="spark-job-fails-with-throttling-in-s3-when-using-mfoc-aws">Spark job fails with throttling in S3 when using MFOC (AWS)</h3><hr /><p>무겁고 높은 로드를 일으키는 job에서, Multipart Upload를 활성화한 upload가 실패할 수 있다.</p><p>Spark Override configuration에 아래와 같은 설정들을 잡아준다.</p><ul><li>해당 작업이 실패할 때, 하둡이 다른 pending된 upload까지 다 abort 시킬 수 있다. 이는 연관된 다른 작업들까지 실패될 수 있으므로, <code class="language-plaintext highlighter-rouge">spark.hadoop.fs.s3a.committer.staging.abort.pending.uploads</code> 설정을 false로 잡아준다. 이후에 Bucket Lifecycle Policy를 통해 실패된 Multipart Uploaded file을 expire시킬 수 있다.<li><code class="language-plaintext highlighter-rouge">spark.hadoop.fs.s3a.committer.threads</code>의 default 값은 8인데, thread의 수를 더 줄여준다.<li><code class="language-plaintext highlighter-rouge">spark.hadoop.fs.s3a.committer.threads.max</code> 값을 위의 thread 수와 맞춰준다. (일반적으로 위의 thread 수를 늘려서 s3 loading 작업을 더 빠르게 만들 수 있지만, S3에서 너무 높은 로드로 실패하는 경우가 생긴다면 이를 줄여서 작게 설정해볼 수 있다.)<li><code class="language-plaintext highlighter-rouge">spark.hadoop.fs.s3a.connection.timeout</code>값을 default 200000 ms에서 더 높은 값으로 잡아줄 수 있다.</ul><h3 id="http-503-slow-down-amazons3exception-aws">HTTP 503 “Slow Down” AmazonS3Exception (AWS)</h3><hr /><p>S3에 스파크로 많은 양의 데이터를 쓰려고 시도하다보면 가끔식 마주치게 되는 에러인 듯 하다. 위의 에러와 같이 엄밀히 말하면 Spark 자체의 에러는 아니지만 S3를 데이터 저장소르 쓰는 경우 스파크로 데이트를 쓰거나 읽을때 발생할 수 있다. prefix마다 초당 3,500개의 PUT/COPY/POST/DELETE 및 5,500개의 GET/HEAD 요청을 넘어갈 때 발생한다.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>java.io.IOException: com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Slow Down (Service: Amazon S3; Status Code: 503; Error Code: 503 Slow Down; Request ID: 2E8B8866BFF00645; S3 Extended Request ID: oGSeRdT4xSKtyZAcUe53LgUf1+I18dNXpL2+qZhFWhuciNOYpxX81bpFiTw2gum43GcOHR+UlJE=), S3 Extended Request ID: oGSeRdT4xSKtyZAcUe53LgUf1+I18dNXpL2+qZhFWhuciNOYpxX81bpFiTw2gum43GcOHR+UlJE=

</pre></table></code></div></div><ol><li>가장 기본적인 해결법으로 버킷의 prefix를 더 나누는 방법이 있다.<div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>s3://awsexamplebucket/images
s3://awsexamplebucket/videos
s3://awsexamplebucket/documents
</pre></table></code></div></div><p>그러면 prefix 3개로 나뉘어져서 해당 버킷에 대해 초당 10,500건의 쓰기 요청 또는 16,500건의 읽기 요청을 할 수 있다. <br /> 이 때 prefix란 bucket + 1 depth까지의 namespace까지를 말한다. 즉 s3://awsexamplebucket/images/prefix_depth2, s3://awsexamplebucket/images/prefix_depth3 으로 2 depth 이하로 prefix를 나누는 경우는 이 로직이 동작하지 않는다. 우리 시스템 같은 경우 이렇게 여러 depth를 들어간 이후 table구조를 구성하고 있기 때문에 한 때 이 에러를 자주 마주쳤다.</p><li>Amazon S3 요청 수 줄이기<br /> 디렉토리 구조를 통으로 바꾸는 것은 간단한 일이 아니기 때문에 우리는 Spark Job의 병렬도를 낮춰서 해결했다. 위와 같은 제약사항을 고려하여 S3 bucket 구조를 설계할 때, 한 bucket에 모든 데이터를 담고 그 아래 prefix를 여러 depth로 쪼개는 것보다 목적에 따라 여러 bucket과 1depth의 prefix를 가져가는 구조로 설계하는 것이 좋아보인다.<li>EMRFS 재시도 제한 증가<div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre>[
 {
   "Classification": "emrfs-site",
   "Properties": {
     "fs.s3.maxRetries": "20",
     "fs.s3.consistent.retryPeriodSeconds": "10",
     "fs.s3.consistent": "true",
     "fs.s3.consistent.retryCount": "5",
     "fs.s3.consistent.metadata.tableName": "EmrFSMetadata"
   }
 }
]
</pre></table></code></div></div></ol><h2 id="reference">Reference</h2><p><a href="https://docs.qubole.com/en/latest/troubleshooting-guide/spark-ts/troubleshoot-spark.html">https://docs.qubole.com/en/latest/troubleshooting-guide/spark-ts/troubleshoot-spark.html</a><br /> <a href="https://medium.com/ibm-data-ai/beginners-troubleshooting-guide-for-spark-ibm-analytics-engine-199019cfc6b4">https://medium.com/ibm-data-ai/beginners-troubleshooting-guide-for-spark-ibm-analytics-engine-199019cfc6b4</a><br /> <a href="https://www.slideshare.net/jcmia1/a-beginners-guide-on-troubleshooting-spark-applications">https://www.slideshare.net/jcmia1/a-beginners-guide-on-troubleshooting-spark-applications</a> <a href="https://aws.amazon.com/ko/premiumsupport/knowledge-center/emr-s3-503-slow-down/">https://aws.amazon.com/ko/premiumsupport/knowledge-center/emr-s3-503-slow-down/</a></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/spark/'>Spark</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/spark/" class="post-tag no-text-decoration" >spark</a> <a href="/tags/troubleshooting/" class="post-tag no-text-decoration" >troubleshooting</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Spark - Troubleshooting Cheatsheet (스파크 - 트러블슈팅 가이드) - Jaemun Jung&url=https://jaemunbro.github.io/posts/troubleshooting-spark/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Spark - Troubleshooting Cheatsheet (스파크 - 트러블슈팅 가이드) - Jaemun Jung&u=https://jaemunbro.github.io/posts/troubleshooting-spark/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Spark - Troubleshooting Cheatsheet (스파크 - 트러블슈팅 가이드) - Jaemun Jung&url=https://jaemunbro.github.io/posts/troubleshooting-spark/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://jaemunbro.github.io/posts/troubleshooting-spark/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/whatis-mlops/">ML - What is MLOps? (MLOps란)</a><li><a href="/posts/blog-migration/">블로그 이사</a><li><a href="/posts/yarn-scheduler/">Hadoop - YARN Scheduler setting (하둡 - YARN 스케쥴러 설정)</a><li><a href="/posts/spark-config-executors/">Spark - Config Executors (스파크 - 최적의 익스큐터 사이즈와 개수 정하기)</a><li><a href="/posts/troubleshooting-spark/">Spark - Troubleshooting Cheatsheet (스파크 - 트러블슈팅 가이드)</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/spark/">spark</a> <a class="post-tag" href="/tags/executor/">executor</a> <a class="post-tag" href="/tags/hadoop/">hadoop</a> <a class="post-tag" href="/tags/ml/">ml</a> <a class="post-tag" href="/tags/mlops/">mlops</a> <a class="post-tag" href="/tags/nosql/">nosql</a> <a class="post-tag" href="/tags/optimization/">optimization</a> <a class="post-tag" href="/tags/scheduler/">scheduler</a> <a class="post-tag" href="/tags/thoughts/">thoughts</a> <a class="post-tag" href="/tags/troubleshooting/">troubleshooting</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/spark-config-executors/"><div class="card-body"> <span class="timeago small" > Apr 30, 2020 <i class="unloaded">2020-04-30T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Spark - Config Executors (스파크 - 최적의 익스큐터 사이즈와 개수 정하기)</h3><div class="text-muted small"><p> Original Post: [Apache Spark] Executor 사이즈와 개수 정하기 에서 옮겨왔습니다. Spark Application을 띄울때 가장 기본적으로 설정해야하는 요소. Executor의 사이즈와 개수는 어떻게 정하는 것이 좋을까? Executor에 관한 몇 가지 기본 전제를 먼저 확인해보자. executor는 캐싱과 실...</p></div></div></a></div><div class="card"> <a href="/posts/spark-basic-optimization/"><div class="card-body"> <span class="timeago small" > May 1 <i class="unloaded">2021-05-01T01:43:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Spark - Core Optimization (스파크 - 최적화)</h3><div class="text-muted small"><p> 스파크의 기본적인 최적화 세팅 방법들에 대해 정리해보자. 본문 작성에 주되게 참조한 소스는 Spark + AI Summit Europe 2019에서 발표한 Databricks의 Daniel Tomes의 세션인 Apache Spark Core – Practical Optimization이다. General Optimization Practical O...</p></div></div></a></div><div class="card"> <a href="/posts/whatis-mlops/"><div class="card-body"> <span class="timeago small" > May 22 <i class="unloaded">2021-05-22T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ML - What is MLOps? (MLOps란)</h3><div class="text-muted small"><p> MLOps가 무엇인고? Medium Blog MLOps가 무엇인고?에 작성했던 글을 옮겨옴. 근래 들어 MLOps라는 용어가 점점 더 보편적이 되어가고 있다. 이것은 또 무엇에 쓰는 물건인고? 한번 알아보자. MLOps의 정의 먼저 한 문장으로 간단히 정의해보면, 개발과 운영을 따로 나누지 않고 개발의 생산성과 운영의 안정성을 최적화하기...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/blog-migration/" class="btn btn-outline-primary" prompt="Older"><p>블로그 이사</p></a> <a href="/posts/spark-basic-optimization/" class="btn btn-outline-primary" prompt="Newer"><p>Spark - Core Optimization (스파크 - 최적화)</p></a></div><script src="https://utteranc.es/client.js" repo="jaemunbro/jaemunbro.github.io" issue-term="pathname" theme="github-dark" crossorigin="anonymous" async> </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2021 <a href="https://github.com/jaemunbro">Jaemun Jung</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/spark/">spark</a> <a class="post-tag" href="/tags/executor/">executor</a> <a class="post-tag" href="/tags/hadoop/">hadoop</a> <a class="post-tag" href="/tags/ml/">ml</a> <a class="post-tag" href="/tags/mlops/">mlops</a> <a class="post-tag" href="/tags/nosql/">nosql</a> <a class="post-tag" href="/tags/optimization/">optimization</a> <a class="post-tag" href="/tags/scheduler/">scheduler</a> <a class="post-tag" href="/tags/thoughts/">thoughts</a> <a class="post-tag" href="/tags/troubleshooting/">troubleshooting</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://jaemunbro.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
