<!DOCTYPE html><html lang="en-US" mode="dark" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="Spark - Core Optimization (스파크 - 최적화)" /><meta name="author" content="Jaemun Jung" /><meta property="og:locale" content="en_US" /><meta name="description" content="스파크의 기본적인 최적화 세팅 방법들에 대해 정리해보자. 본문 작성에 주되게 참조한 소스는 Spark + AI Summit Europe 2019에서 발표한 Databricks의 Daniel Tomes의 세션인 Apache Spark Core – Practical Optimization이다." /><meta property="og:description" content="스파크의 기본적인 최적화 세팅 방법들에 대해 정리해보자. 본문 작성에 주되게 참조한 소스는 Spark + AI Summit Europe 2019에서 발표한 Databricks의 Daniel Tomes의 세션인 Apache Spark Core – Practical Optimization이다." /><link rel="canonical" href="https://jaemunbro.github.io/posts/spark-basic-optimization/" /><meta property="og:url" content="https://jaemunbro.github.io/posts/spark-basic-optimization/" /><meta property="og:site_name" content="Jaemun Jung" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-05-01T01:43:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Spark - Core Optimization (스파크 - 최적화)" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"Jaemun Jung"},"description":"스파크의 기본적인 최적화 세팅 방법들에 대해 정리해보자. 본문 작성에 주되게 참조한 소스는 Spark + AI Summit Europe 2019에서 발표한 Databricks의 Daniel Tomes의 세션인 Apache Spark Core – Practical Optimization이다.","url":"https://jaemunbro.github.io/posts/spark-basic-optimization/","@type":"BlogPosting","headline":"Spark - Core Optimization (스파크 - 최적화)","dateModified":"2021-05-06T02:32:50+09:00","datePublished":"2021-05-01T01:43:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://jaemunbro.github.io/posts/spark-basic-optimization/"},"@context":"https://schema.org"}</script><title>Spark - Core Optimization (스파크 - 최적화) | Jaemun Jung</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-WKRD9Q3FPK"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-WKRD9Q3FPK'); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://media-exp1.licdn.com/dms/image/C5103AQGerVQv-H9XRg/profile-displayphoto-shrink_400_400/0/1586752686385?e=1640217600&v=beta&t=CDknpaAWkjeC1KFgz9zAhkxrhUhAvxCrcjnZJtElD3U" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Jaemun Jung</a></div><div class="site-subtitle font-italic">Data Engineer. Let the data flow!</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/jaemunbro" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['jaemunbro','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://jaemunbro.medium.com/" aria-label="medium" target="_blank" rel="noopener"> <i class="fab fa-medium"></i> </a> <a href="https://www.linkedin.com/in/ryan-jaemun-jung-055350b3/" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Spark - Core Optimization (스파크 - 최적화)</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Spark - Core Optimization (스파크 - 최적화)</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Jaemun Jung </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sat, May 1, 2021, 1:43 AM +0900" prep="on" > May 1 <i class="unloaded">2021-05-01T01:43:00+09:00</i> </span></div><div> <span> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Thu, May 6, 2021, 2:32 AM +0900" prefix="Updated " > May 6 <i class="unloaded">2021-05-06T02:32:50+09:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2399 words">13 min</span></div></div><div class="post-content"><p>스파크의 기본적인 최적화 세팅 방법들에 대해 정리해보자. 본문 작성에 주되게 참조한 소스는 Spark + AI Summit Europe 2019에서 발표한 Databricks의 Daniel Tomes의 세션인 <a href="https://databricks.com/session_eu19/apache-spark-core-practical-optimization">Apache Spark Core – Practical Optimization</a>이다.</p><h1 id="general-optimization">General Optimization</h1><hr /><p>Practical Optimization에 관해서 깊이 파보기 전에, 기본적인 최적화 방법들에 대해서 먼저 간단히 살펴보자.</p><h3 id="file-format-최적화">File Format 최적화</h3><ul><li>Parquet, ORC와 같은 columnar file 활용<li>splittable file format 사용 (snappy, bzip2와 같은 compression format)<li>너무 많은 small file은 compaction 한다.</ul><h3 id="parallelism">Parallelism</h3><ul><li>데이터 사이즈에 맞춘 스파크 파티션 생성. 너무 적은 파티션 수는 executor를 idle하게 만들 수 있고 반대로 너무 많은 파티션은 task scheduling 오버헤드를 지나치게 높게 만들 수 있다.<li>executor 최소한 2-3개 이상의 코어를 할당<li><code class="language-plaintext highlighter-rouge">spark.sql.shuffle.partitions</code> 기본값 200은 빅데이터 프로덕션 환경에서는 너무 작으므로 기본적으로 튜닝이 필요하다.</ul><h3 id="shuffle-줄이기">Shuffle 줄이기</h3><p>shuffle은 네트워크와 disk I/O를 포함하는 노드간 데이터 이동을 불러일으키는 가장 비싼 연산이다. shuffle을 줄이는 것이 튜닝의 시작이다.</p><ul><li><code class="language-plaintext highlighter-rouge">spark.sql.shuffle.partitions</code>을 튜닝한다.<li>각 task 사이즈가 너무 저지지 않도록 input data를 파티셔닝한다.<li>일반적으로, 파티션당 100MB에서 200MB 사이를 타게팅하도록 한다.<li><code class="language-plaintext highlighter-rouge">spark.sql.shuffle.partitions</code> = (shuffle stage input size/target size)/total cores) * total cores</ul><h3 id="filterreduce-dataset-size">Filter/Reduce dataSet size</h3><ul><li>partition된 데이터를 활용한다.<li>최대한 이른 stage에서 데이터를 filter out 한다.</ul><h3 id="적절한-cache-사용">적절한 Cache 사용</h3><ul><li>pipeline에서 여러번 계산이 필요한 df에서 활용한다.<li>unpersist를 하자.</ul><h3 id="join">Join</h3><ul><li>BroadcastHashJoin을 최대한 활용하자. 가장 성능이 빠른 Join이다.</ul><h3 id="cluster-리소스-튜닝">Cluster 리소스 튜닝</h3><ul><li>spark.driver.memory, executor-memory, num-executors, and executor-cores 튜닝</ul><h3 id="비싼-연산은-피하자">비싼 연산은 피하자</h3><ul><li>order by는 필수적인 경우만 쓴다.<li>모든 컬럼을 선택하기 위한 (*)는 지양하고, 필요한 컬럼을 선택해서 쓴다.<li>count()도 꼭 필요한 경우에만.</ul><h3 id="skew--아래-advanced-optimization-참조">Skew (아래 Advanced Optimization 참조)</h3><ul><li>salting 통해 해결<li>partition이 불균형한 경우, 균형잡힌 파티션을 재생성하기 위해 repartition을 하고 cache해두는 것을 고려해볼 수도 있다<li>Spark 3.0을 쓴다..ㅎ<li>SparkUI에서 partition size와 task duration을 확인하자</ul><h3 id="udf">UDF</h3><ul><li>UDF 사용은 최대한 지양한다. (아래 Advanced Optimization 참조)</ul><h1 id="practical-optimization">Practical Optimization</h1><h2 id="하드웨어-스펙에-대한-이해">하드웨어 스펙에 대한 이해</h2><hr /><ul><li><strong>Core Count &amp; Speed</strong><li><strong>Memory Per Core</strong> (메모리당 코어가 얼마나 되는가)<li>local disk type, count, size, speed<li>network speed, toplology<li>cost / core / hour</ul><h2 id="get-a-baseline">Get A Baseline</h2><hr /><ul><li>Is your action efficient?<ul><li>Long Stages, Spills, Laggard Tasks<br /> duration으로 sorting해서 가장 오래 돌고 있는 Stage를 파악하는 것부터 시작할 수 있다.<br /> disk spill이 심하게 일어나고 있는 Stage인 경우를 찾는다. 보통 가장 오래 도는 Job과 동일한 경우가 많다.</ul><li>CPU Utilization<ul><li>Ganglia / Yarn<br /> CPU 활용률이 너무 낮다면, CPU 활용률이 70% 내외로 활용될 수 있도록 타겟으로 잡아볼 수 있다.</ul></ul><h2 id="데이터-스캔-최소화---minimize-data-scans">데이터 스캔 최소화 - Minimize Data Scans</h2><hr /><ul><li>가장 간단하지만 가장 중요한 최적화 기법<br /> <strong>Lazy loading</strong> - 데이터를 파티셔닝을 최대한 필터하고 로딩해서 사용한다.<li>Hive Partition<br /> <strong>Partition pruning</strong>을 통한 스캔 대상 데이터 최소화<li>Bucketing (Only for experts - 제대로 유지하는 것이 거의 불가능에 가까움..)</ul><h2 id="spark-partitions---inputshuffleoutput">Spark Partitions - Input/Shuffle/Output</h2><hr /><p>스파크 파티션을 컨트롤하는 두가지 핵심은</p><ol><li><strong>Spill을 피하도록 한다</strong><li><strong>최대한의 Core를 활용할 수 있도록 한다</strong> 이다. 데이터의 Input 단계부터 Shuffle 단계, Output 단계로 나눠서 알아보자.<h4 id="1-input">(1) Input</h4><ul><li>Size를 컨트롤한다.<br /> <code class="language-plaintext highlighter-rouge">spark.sql.file.maxPartitionBytes</code> default value : 128MB</ul><ul><li>Increase Parallelism: 코어의 활용률을 병렬도를 더 올리기 위해 쪼개서 읽을 수 있다. 예시) <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/29077671/116790207-11a69400-aaee-11eb-8b26-79e65539e52c.png" alt="image" /> shuffle이 없는 map job이므로 오직 read/write 속도에만 dependant한 task인데, 더 빠르게 처리하기 위해 maxPartitionSize를 core 수에 맞게 튜닝했고 그것만으로 시간을 50% 줄일 수 있었다. 더 많은 코어가 나누어서 처리했기 때문이다.<li>Heavily Nested/Repetitive Data: 메모리에서 풀어냈을때 데이터가 커질 수 있으므로 더 작게 읽는 것이 필요할 수도 있다.<li>Generating Data - Explode: 이 역시 새로운 데이터 컬럼을 만들면서 데이터가 메모리 상에서 커질 수 있으므로.<li>Source Structure is not optimal(upstream)<li>UDFs</ul></ol><h4 id="2-shuffle">(2) Shuffle</h4><ul><li>Count를 컨트롤한다.<li><code class="language-plaintext highlighter-rouge">spark.sql.shuffle.partitions</code> default value : 200<li>가장 큰 셔플 스테이지의 타겟 사이즈를 파티션당 200MB 이하로 잡는 것이 적절하다. <br /> (target size &lt;= 200 MB/partition)<ul><li><p>예시를 들어보자. Shuffle Stage Input = 210GB<br /> 210000MB / 200MB = 1050 -&gt; <code class="language-plaintext highlighter-rouge">spark.conf.set("spark.sql.shuffle.partitions", 1050)</code><br /> 하지만 만약 클러스터의 가용 코어가 2000 이라면 다 활용하면 더 좋다.<br /> -&gt; <code class="language-plaintext highlighter-rouge">spark.conf.set("spark.sql.shuffle.partitions", 2000)</code></p><li>또 다른 예시 - spark history server의 stage 모니터링 <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/29077671/116789923-7c56d000-aaec-11eb-9fc7-0e7b1fcbe557.png" alt="image" /> 위 예시의 우측 Summary Metrics를 보면 Median 값이 270MB이다. 아주 나쁘진 않지만 그래도 파티션이 부족하다고 봐야한다. 위의 예시에서 stage 19와 stage 20이 stage 21의 셔플의 소스이므로, 19와 20의 shuffle write이 21의 shuffle input이 라고 볼 수 있다. 간단하게 이야기해서, shuffle spill(memory/disk)가 일어나고 있다면 파티션이 더 필요하다고 이해해도 좋다.<li>partition count = stage input data / target size</ul></ul><h4 id="3-output">(3) Output</h4><ul><li>Count를 컨트롤한다.<li>coalesce(n) : 2000개의 partition이 shuffle하고 나서, write할 때 100개가 나눠서 할 수 있도록.<li>Repartition(n) : partition을 증가시킬 때 사용. shuffle을 발생시키므로 꼭 필요한 경우가 아니면 사용하지 말자.<li>df.write.option(“maxRecordsPerFile”, N) : 추천하는 방법은 아님. <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/29077671/116790347-998c9e00-aaee-11eb-85be-baf026979fc3.png" alt="image" /> 전체 160GB의 파일을 처리하는데 10개의 코어가 1.6GB씩 처리할 때와 100개의 코어가 처리할 때의 차이는 아주 크다.</ul><h2 id="skew-join-optimization">Skew Join Optimization</h2><hr /><p>어떤 파티션이 다른 파티션보다 훨씬 큰 경우. 예시) 어떤 키 하나에는 수백만개의 count가 몰려 있고, 나머지 키에는 수십개 정도씩만 있다고 가정하자. <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/29077671/116791009-85e33680-aaf2-11eb-9ba1-a4cd5196d7b2.png" alt="image" /> <strong>Salting</strong>이라 불리는 방법을 통해 해결해볼 수 있다. 노이즈 데이터를 뿌려넣는다는 의미이다.</p><ul><li>0부터 spark.sql.suffle.partitoins - 1 사이의 random int값을 가진 column을 양쪽 데이터프레임에 생성한다.<li>Join 조건에 새로운 salting column을 포함한다.<li>result 표출 시 salting column을 drop한다.<div class="language-scala highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="nv">df</span><span class="o">.</span><span class="py">groupBy</span><span class="o">(</span><span class="s">"city"</span><span class="o">,</span> <span class="s">"state"</span><span class="o">).</span><span class="py">agg</span><span class="o">(&lt;</span><span class="nf">f</span><span class="o">(</span><span class="n">x</span><span class="o">)&gt;).</span><span class="py">orderBy</span><span class="o">(</span><span class="nv">co</span><span class="o">.</span><span class="py">desc</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">saltVal</span> <span class="k">=</span> <span class="nf">random</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="nv">spark</span><span class="o">.</span><span class="py">conf</span><span class="o">.</span><span class="py">get</span><span class="o">(</span><span class="n">org</span><span class="o">...</span><span class="py">shuffle</span><span class="o">.</span><span class="py">partitions</span><span class="o">)</span> <span class="o">-</span> <span class="mi">1</span><span class="o">)</span>
<span class="nv">df</span><span class="o">.</span><span class="py">withColumn</span><span class="o">(</span><span class="s">"salt"</span><span class="o">,</span> <span class="nf">lit</span><span class="o">(</span><span class="n">saltVal</span><span class="o">))</span>
  <span class="o">.</span><span class="py">groupBy</span><span class="o">(</span><span class="s">"city"</span><span class="o">,</span> <span class="s">"state"</span><span class="o">,</span> <span class="s">"salt"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">agg</span><span class="o">(&lt;</span><span class="nf">f</span><span class="o">(</span><span class="n">x</span><span class="o">)&gt;)</span>
  <span class="o">.</span><span class="py">drop</span><span class="o">(</span><span class="s">"salt"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">orderBy</span><span class="o">(</span><span class="nv">col</span><span class="o">.</span><span class="py">desc</span><span class="o">)</span>
</pre></table></code></div></div><li>Spark3.0부터는 join 시 동적으로 splitting - replicating등의 작업을 통해 재분배하는 조건이 생겼다. <code class="language-plaintext highlighter-rouge">spark.sql.adaptive.skewJoin.enabled</code> default: true <code class="language-plaintext highlighter-rouge">spark.sql.adaptive.skewJoin.skewedPartitionFactor</code> default: 10 <code class="language-plaintext highlighter-rouge">spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes</code> default 256MB</ul><h2 id="minimize-data-scans-persistence">Minimize Data Scans (Persistence)</h2><hr /><ul><li>Persistence는 무료가 아니다.<li>반복작업이 있는 경우에 사용한다.<li>기본 <code class="language-plaintext highlighter-rouge">df.cache == df.persist(StorageLevel.MEMORY_AND_DISK)</code><li>다른 타입들의 장단점에 대해서도 알아보자.<ul><li>Default StorageLevel.MEMORY_AND_DISK<br /> (deserialized)<li>deserialized = Faster = Bigger<li>serialized = Slower = Smaller</ul><li><strong>df.unpersist 를 잊지말자!!</strong><br /> cache memory를 사용하는 만큼 working memory가 줄어들 것이므로.</ul><h2 id="join-optimization">Join Optimization</h2><hr /><ul><li>SortMerge Join : 양쪽 데이터가 다 클 때<li>Broadcast Join : 한쪽 데이터가 작을때<ul><li>옵티마이저에 의해 자동으로 활성화됨 (one side &lt; spark.sql.autoBroadcastJoinThreshold) 기본값은 10M.<li>Risk<ul><li>Not Enough Driver Memory<li>DF &gt; spark.driver.maxResultSize<li>DF &gt; single executor available working memory</ul><li><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/29077671/116790846-8a5b1f80-aaf1-11eb-9ccf-f82a30430e94.png" alt="image" /><ul><li>broadcast join을 조심해야하는 이유 : driver에서 hashmap format datafame으로 바꿔서 각 executor로 보낸다. hashmap을 만들면서 기존에 compression이 되어 있던 것도 풀리므로 데이터 사이즈도 처음 partition 안에 있을 때보다 몇배 커진 상태가 될 수 있다. (e.g., 126MB -&gt; 270MB)</ul></ul></ul><h2 id="broadcastnestedloopjoin-bnlj">BroadcastNestedLoopJoin (BNLJ)</h2><hr /><p>SparkSQL에서는 NOT IN 조건 대신 NOT EXISTS를 사용하라. 훨씬 효율적이다. <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/29077671/116791238-db6c1300-aaf3-11eb-854b-fe73059567b4.png" alt="image" /></p><h2 id="비싼-오퍼레이션을-제외시키자---omit-expensive-ops">비싼 오퍼레이션을 제외시키자 - Omit Expensive Ops</h2><hr /><p>튜닝의 시작을 IntelliJ에서 아래 키워드들을 찾는 것부터 해볼 수도 있다.</p><ul><li>Repartition<br /> coalesce를 쓰거나 shuffle partition count 세팅을 바꿔서 써라.<li>count()<br /> 진짜 필요한 경우에만 써라.<br /> 습관적으로 많이 쓰긴 하지만, 프로덕션 배포 전에 제외시키는 걸 잊지 말자!<li>distinctCount -&gt; 꼭 정확한 숫자가 필요한 것이 아니라면 가능하면 approxCountDistinct()를 써라.<br /> 생각해보면 2% 내외의 오차가 발생하는 것을 감수할 수 있는 경우가 많다.<li>distinct<ul><li>distinct 대신 dropDuplicates을 써라.<li>dropDuplicates를 JOIN 전에 써라.<li>dropDuplicates를 groupBy 전에 써라.</ul></ul><h3 id="udf-penalties">UDF penalties</h3><ul><li>UDF 사용은 최대한 피하는게 좋다.<li>일반적으로 scala udf가 python udf보다 빠르다. r udf는 가~끔 작동한다.<li>org.apache.spark.sql.functions를 최대한 활용하자.<li>UDF 만들기 전에 PandasUDF(vectorized UDFs)에 원하는 기능이 없는지 알아보자.</ul><h3 id="advanced-parallelism">Advanced Parallelism</h3><ul><li>Driver Parallelism<br /> 델타 처리를 위한 예시. executor로 넘기기 전에 driver부터 multi thread로 일할 수 있도록 해준다. <br /> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/29077671/116791534-0f483800-aaf6-11eb-9cd8-fd0d86925c62.png" alt="image" width="60%" height="60%" /><li>Horizontal Parallelsim<li>Executor Parallelism</ul><h4 id="더-알아보기-좋은-글">더 알아보기 좋은 글</h4><p>GC tuning: <a href="https://databricks.com/blog/2015/05/28/tuning-java-garbage-collection-for-spark-applications.html">https://databricks.com/blog/2015/05/28/tuning-java-garbage-collection-for-spark-applications.html</a></p><h2 id="reference">Reference</h2><p><a href="https://databricks.com/session_eu19/apache-spark-core-practical-optimization">https://databricks.com/session_eu19/apache-spark-core-practical-optimization</a> <a href="https://developer.ibm.com/technologies/artificial-intelligence/ blogs/spark-performance-optimization-guidelines/">https://developer.ibm.com/technologies/artificial-intelligence/blogs/spark-performance-optimization-guidelines/</a> <a href="https://spark.apache.org/docs/latest/sql-performance-tuning.html">https://spark.apache.org/docs/latest/sql-performance-tuning.html</a> <a href="https://spark.apache.org/docs/latest/tuning.html">https://spark.apache.org/docs/latest/tuning.html</a></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/spark/'>Spark</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/spark/" class="post-tag no-text-decoration" >spark</a> <a href="/tags/optimization/" class="post-tag no-text-decoration" >optimization</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Spark - Core Optimization (스파크 - 최적화) - Jaemun Jung&url=https://jaemunbro.github.io/posts/spark-basic-optimization/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Spark - Core Optimization (스파크 - 최적화) - Jaemun Jung&u=https://jaemunbro.github.io/posts/spark-basic-optimization/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Spark - Core Optimization (스파크 - 최적화) - Jaemun Jung&url=https://jaemunbro.github.io/posts/spark-basic-optimization/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://jaemunbro.github.io/posts/spark-basic-optimization/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/whatis-mlops/">ML - What is MLOps? (MLOps란)</a><li><a href="/posts/blog-migration/">블로그 이사</a><li><a href="/posts/yarn-scheduler/">Hadoop - YARN Scheduler setting (하둡 - YARN 스케쥴러 설정)</a><li><a href="/posts/spark-config-executors/">Spark - Config Executors (스파크 - 최적의 익스큐터 사이즈와 개수 정하기)</a><li><a href="/posts/troubleshooting-spark/">Spark - Troubleshooting Cheatsheet (스파크 - 트러블슈팅 가이드)</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/spark/">spark</a> <a class="post-tag" href="/tags/executor/">executor</a> <a class="post-tag" href="/tags/hadoop/">hadoop</a> <a class="post-tag" href="/tags/ml/">ml</a> <a class="post-tag" href="/tags/mlops/">mlops</a> <a class="post-tag" href="/tags/nosql/">nosql</a> <a class="post-tag" href="/tags/optimization/">optimization</a> <a class="post-tag" href="/tags/scheduler/">scheduler</a> <a class="post-tag" href="/tags/thoughts/">thoughts</a> <a class="post-tag" href="/tags/troubleshooting/">troubleshooting</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/spark-config-executors/"><div class="card-body"> <span class="timeago small" > Apr 30, 2020 <i class="unloaded">2020-04-30T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Spark - Config Executors (스파크 - 최적의 익스큐터 사이즈와 개수 정하기)</h3><div class="text-muted small"><p> Original Post: [Apache Spark] Executor 사이즈와 개수 정하기 에서 옮겨왔습니다. Spark Application을 띄울때 가장 기본적으로 설정해야하는 요소. Executor의 사이즈와 개수는 어떻게 정하는 것이 좋을까? Executor에 관한 몇 가지 기본 전제를 먼저 확인해보자. executor는 캐싱과 실...</p></div></div></a></div><div class="card"> <a href="/posts/troubleshooting-spark/"><div class="card-body"> <span class="timeago small" > Apr 30 <i class="unloaded">2021-04-30T01:43:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Spark - Troubleshooting Cheatsheet (스파크 - 트러블슈팅 가이드)</h3><div class="text-muted small"><p> 스파크의 문제 사례들과 그 해결 방법들에 대해 알아보자. 문제 케이스들은 일부 직접 겪은 것들과 본문 하단 링크의 케이스들을 취합하였다. Troubleshooting Tips 트러블슈팅을 위해 verbose mode를 활용하자 spark-submit --driver-memory 10g --verbose --master yarn --executor...</p></div></div></a></div><div class="card"> <a href="/posts/whatis-mlops/"><div class="card-body"> <span class="timeago small" > May 22 <i class="unloaded">2021-05-22T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ML - What is MLOps? (MLOps란)</h3><div class="text-muted small"><p> MLOps가 무엇인고? Medium Blog MLOps가 무엇인고?에 작성했던 글을 옮겨옴. 근래 들어 MLOps라는 용어가 점점 더 보편적이 되어가고 있다. 이것은 또 무엇에 쓰는 물건인고? 한번 알아보자. MLOps의 정의 먼저 한 문장으로 간단히 정의해보면, 개발과 운영을 따로 나누지 않고 개발의 생산성과 운영의 안정성을 최적화하기...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/troubleshooting-spark/" class="btn btn-outline-primary" prompt="Older"><p>Spark - Troubleshooting Cheatsheet (스파크 - 트러블슈팅 가이드)</p></a> <a href="/posts/yarn-scheduler/" class="btn btn-outline-primary" prompt="Newer"><p>Hadoop - YARN Scheduler setting (하둡 - YARN 스케쥴러 설정)</p></a></div><script src="https://utteranc.es/client.js" repo="jaemunbro/jaemunbro.github.io" issue-term="pathname" theme="github-dark" crossorigin="anonymous" async> </script></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#main > div.row:first-child > div:first-child img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2021 <a href="https://github.com/jaemunbro">Jaemun Jung</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/spark/">spark</a> <a class="post-tag" href="/tags/executor/">executor</a> <a class="post-tag" href="/tags/hadoop/">hadoop</a> <a class="post-tag" href="/tags/ml/">ml</a> <a class="post-tag" href="/tags/mlops/">mlops</a> <a class="post-tag" href="/tags/nosql/">nosql</a> <a class="post-tag" href="/tags/optimization/">optimization</a> <a class="post-tag" href="/tags/scheduler/">scheduler</a> <a class="post-tag" href="/tags/thoughts/">thoughts</a> <a class="post-tag" href="/tags/troubleshooting/">troubleshooting</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://jaemunbro.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
