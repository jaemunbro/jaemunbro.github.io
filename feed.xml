<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jaemun Jung</title>
    <description>description.. nothing yet.</description>
    <link>https://jaemunbro.github.io/</link>
    <atom:link href="https://jaemunbro.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 25 Oct 2021 23:28:16 +0900</pubDate>
    <lastBuildDate>Mon, 25 Oct 2021 23:28:16 +0900</lastBuildDate>
    <generator>Jekyll v4.2.1</generator>
    
      <item>
        <title>ML - What is MLOps? (MLOps란)</title>
        <description>&lt;h1 id=&quot;mlops가무엇인고&quot;&gt;MLOps가 무엇인고?&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Medium Blog &lt;a href=&quot;https://medium.com/p/84f68e4690be/edit&quot;&gt;MLOps가 무엇인고?&lt;/a&gt;에 작성했던 글을 옮겨옴.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;근래 들어 MLOps라는 용어가 점점 더 보편적이 되어가고 있다.
이것은 또 무엇에 쓰는 물건인고? 한번 알아보자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;mlops의-정의&quot;&gt;MLOps의 정의&lt;/h1&gt;
&lt;p&gt;먼저 한 문장으로 간단히 정의해보면,
개발과 운영을 따로 나누지 않고 개발의 생산성과 운영의 안정성을 최적화하기 위한 문화이자 방법론이 DevOps이며, 이를 ML 시스템에 적용한 것이 MLOps이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/138129733-32356180-a815-4801-b3b8-eadd21700ecd.png&quot; alt=&quot;image&quot; title=&quot;DevOps의 Dev-Ops-QA간 벤다이어그램. 위의 Dev를 ML로 살짝 바꾸면 MLOps(from https://en.wiktionary.org/wiki/DevOps)&quot; /&gt;&lt;em&gt;DevOps의 Dev-Ops-QA간 벤다이어그램. 위의 Dev를 ML로 살짝 바꾸면 MLOps?(from https://en.wiktionary.org/wiki/DevOps)&lt;/em&gt;&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;
MLOps는 ML의 전체 Lifecycle를 관리해야 한다.
아래 그림은 IT Production을 위한 AI Lifecycle을 표현한 NVIDIA의 자료다.
MLOps란 단순히 ML 모델뿐만 아니라, 데이터를 수집하고 분석하는 단계(Data Collection, Ingestion, Analysis, Labeling, Validation, Preparation), 그리고 ML 모델을 학습하고 배포하는 단계(Model Training, Validation, Deployment)까지 전 과정을 AI Lifecycle로 보고, MLOps의 대상으로 보고 있다. 
ML에 기여하는 Engineer들(Data Scientist, Data Engineer, SW Engineer)이 이 Lifecycle을 관리하고 모니터링해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/138129756-d2121552-6c80-4662-8a2a-bcdaaf86f043.png&quot; alt=&quot;image&quot; title=&quot;MLOPS by NVIDIA(from https://blogs.nvidia.com/blog/2020/09/03/what-is-mlops/)&quot; /&gt;&lt;em&gt;MLOPS by NVIDIA(from https://blogs.nvidia.com/blog/2020/09/03/what-is-mlops/)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;
머신러닝을 엔터프라이즈 레벨에서 서비스에 구현하고자 한다면, MLOps는 선택이 아니라 반드시 구현해야하는 방향이다. 최고 모범사례까지는 안되더라도 최소한 어느 정도 수준까지는. 따라서 MLOps라는 키워드 자체는 시간이 지나면 바뀔 수도 있겠지만, 최소한 지향점은 바뀌지 않을 필수적인 것으로 생각된다.
아래 Google의 자료를 통해 MLOps의 구성과 발전 방향에 대해 조금 더 자세히 알아보자.&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;아래는 ML시스템에 일반적으로 바람직한 MLOps를 구성하기 위한 필요 요소와 그 발전 방향에 대해서 Google Cloud의 자료 &lt;a href=&quot;https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning&quot;&gt;MLOps: Continuous delivery and automation pipelines in machine learning&lt;/a&gt;를 요약, 정리했습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;ml-시스템의요소&quot;&gt;ML 시스템의 요소&lt;/h1&gt;
&lt;p&gt;머신러닝 시스템을 프로덕션 환경에 적용하고 운영하기 위해서는 단순히 좋은 머신러닝 모델만으로 가능한 것이 아니다. 머신러닝 모델이 ML 시스템의 핵심이기는 하지만, 전체 프로덕션 ML 시스템의 운영을 고려하면 모델 학습 자체는 오히려 작은 부분을 차지한다고 이야기하기도 한다. 모델을 운영하기 위해 기반 데이터와 인프라를 포함한 모든 시스템이 유기적으로 돌아가야 한다.
&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/138129766-d822c7c7-dcc9-4021-9e80-b2d898e5e7b3.png&quot; alt=&quot;image&quot; title=&quot;ML 시스템의 요소(Hidden Technical Debt in Machine Learning Systems)&quot; /&gt;&lt;em&gt;ML 시스템의 요소(Hidden Technical Debt in Machine Learning Systems)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;위와 같은 ML 시스템의 운영을 위해 DevOps의 원칙을 적용한 것이 MLOps이다.&lt;/p&gt;
&lt;h1 id=&quot;devops-vsmlops&quot;&gt;DevOps vs MLOps&lt;/h1&gt;
&lt;p&gt;MLOps는 아래와 같은 점들에서 소프트웨어 시스템과 차이를 가진다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Testing
일반적인 단위, 통합 테스트 외에 데이터 검증, 학습된 모델 품질 평가, 모델 검증이 추가로 필요하다.&lt;/li&gt;
  &lt;li&gt;Deployment
오프라인에서 학습된 ML모델을 배포하는 수준에 그치는 것이 아니라, 새 모델을 재학습하고, 검증하는 과정을 자동화해야 한다.&lt;/li&gt;
  &lt;li&gt;Production
일반적으로 알고리즘과 로직의 최적화를 통해 최적의 성능을 낼 수 있는 소프트웨어 시스템과 달리, ML 모델은 이에 더해서 지속적으로 진화하는 data profile 자체만으로도 성능이 저하될 수 있다. 
즉, 기존 소프트웨어 시스템보다 더 다양한 이유로 성능이 손상될 수 있으므로, 데이터의 summary statistics를 꾸준히 추적하고, 모델의 온라인 성능을 모니터링하여 값이 기대치를 벗어나면 알림을 전송하거나 롤백을 할 수 있어야 한다.&lt;/li&gt;
  &lt;li&gt;CI (Continuous Integration)
CI는 code와 components뿐만 아니라 data, data schema, model에 대해 모두 테스트되고 검증되어야 한다.&lt;/li&gt;
  &lt;li&gt;CD (Continuous Delivery)
단일 소프트웨어 패키지가 아니라 ML 학습 파이프라인 전체를 배포해야한다.&lt;/li&gt;
  &lt;li&gt;CT (Continuous Training)
ML 시스템만의 속성으로, 모델을 자동으로 학습시키고 평가하는 단계이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;data-science-steps-forml&quot;&gt;Data science steps for ML&lt;/h1&gt;
&lt;p&gt;먼저 business use case와 success criteria들을 정하고 나서 ML 모델을 프로덕션에 배포하기까지, 수동이든 자동이든, 모든 ML 프로젝트에는 다음과 같은 스텝들이 수반된다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Data Extraction(데이터 추출)
데이터 소스에서 관련 데이터 추출&lt;/li&gt;
  &lt;li&gt;Data Analysis(데이터 분석)
데이터의 이해를 위한 탐사적 데이터 분석(EDA) 수행
모델에 필요한 데이터 스키마 및 특성 이해&lt;/li&gt;
  &lt;li&gt;Data Preparation(데이터 준비)
데이터의 학습, 검증, 테스트 세트 분할&lt;/li&gt;
  &lt;li&gt;Model Training(모델 학습)
다양한 알고리즘 구현, 하이퍼 파라미터 조정 및 적용
output은 학습된 모델.&lt;/li&gt;
  &lt;li&gt;Model Evaluation(모델 평가)
holdout test set에서 모델을 평가
output은 모델의 성과 평가 metric.&lt;/li&gt;
  &lt;li&gt;Model Validation(모델 검증)
기준치 이상의 모델 성능이 검증되고, 배포에 적합한 수준인지 검증&lt;/li&gt;
  &lt;li&gt;Model Serving(모델 서빙)
    &lt;ul&gt;
      &lt;li&gt;온라인 예측을 제공하기 위해 REST API가 포함된 마이크로 서비스&lt;/li&gt;
      &lt;li&gt;배치 예측 시스템&lt;/li&gt;
      &lt;li&gt;모바일 서비스의 embedded 모델&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Model Monitoring(모델 모니터링)
모델의 예측 성능을 모니터링&lt;br /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/138129776-d5286102-6f05-4b55-81c3-6aa011f1d8db.png&quot; alt=&quot;image&quot; title=&quot;MS Azure의 자료도 참고해보자. Google의 자료와 정의하는 이름과 부수적인 스텝의 차이가 있지만 ML Lifecycle은 결국 모두 같은 필수적인 스텝들을 가진다(from 애저듣보잡 MLOps 101)&quot; /&gt;&lt;em&gt;MS Azure의 자료도 참고해보자. Google의 자료와 정의하는 이름과 부수적인 스텝의 차이가 있지만 ML Lifecycle은 결국 모두 같은 필수적인 스텝들을 가진다(from 애저듣보잡 MLOps 101)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
위와 같은 ML 프로세스의 자동화 수준에 따라 해당 ML 시스템의 성숙도를 평가해볼 수 있다.
Google은 가장 보편적인 수동 적용 단계부터 ML과 CI/CD pipeline을 모두 자동화하는 단계까지 성숙도를 세 단계의 레벨로 나누어서 제시하고 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h1 id=&quot;mlops-level-0-manualprocess&quot;&gt;MLOps level 0: Manual Process&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/138129799-da62ce84-98f3-4c0a-8b0d-f166865a91a2.png&quot; alt=&quot;image&quot; title=&quot;MLOps Level 0 : Manual process&quot; /&gt;&lt;em&gt;MLOps Level 0 : Manual process&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;데이터 추출과 분석, 모델 학습, 검증을 포함한 모든 단계가 수동&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ML과 Operation간 disconnection&lt;/strong&gt; : 데이터 사이언티스트가 모델을 아티팩트로 전달하고, 엔지니어가 low latency로 프로덕션 환경에 배포. training-serving skew가 발생할 수 있다.&lt;/li&gt;
  &lt;li&gt;Infrequent release iteration : 새 모델 버전의 배포가 뜨문뜨문 비정기적으로 발생한다.&lt;/li&gt;
  &lt;li&gt;No CI : 변경이 많지 않으므로 CI가 고려되지 않는다. 스크립트 수행이나 노트북에서 개인적으로 테스트를 수행한다.&lt;/li&gt;
  &lt;li&gt;No CD : 배포가 자주 없으므로 CD까지 필요하지 않다.&lt;/li&gt;
  &lt;li&gt;Active performance monitoring의 부재 : 로그나 모델의 예측 성능 등을 모니터링하지 않는다. 모델의 성능이 저하되거나 모델이 이상동작 하는 것을 감지할 수 없다.&lt;br /&gt;
&lt;br /&gt;
    &lt;h3 id=&quot;level-0의-challenges&quot;&gt;Level 0의 Challenges&lt;/h3&gt;
    &lt;p&gt;모델이 프로덕션 환경에 배포되면 실제 환경과 데이터의 변화들로 인해서 실패하는 경우가 많이 생길 수 있다. (원인에 대해서 더 자세히 알아보려면 : &lt;a href=&quot;https://www.forbes.com/sites/forbestechcouncil/2019/04/03/why-machine-learning-models-crash-and-burn-in-production/&quot;&gt;Why Machine Learning Models Crash and Burn in Production.&lt;/a&gt;)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;모델의 정확도를 프로덕션 환경에서도 유지하려면 다음과 같은 노력을 해야한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;프로덕션 환경의 모델 품질 모니터링 : 성능 저하 및 모델의 staleness(신선도가 떨어짐)를 감지&lt;/li&gt;
  &lt;li&gt;최신 데이터로 모델을 재학습&lt;/li&gt;
  &lt;li&gt;새로운 feature의 추출, 모델 아키텍처, 하이퍼파라미터 등의 새로운 구현을 계속 시도&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h1 id=&quot;mlops-level-1-ml-pipeline-automation&quot;&gt;MLOps level 1: ML pipeline automation&lt;/h1&gt;
&lt;p&gt;Level 1의 목표는 ML 파이프라인을 자동화하여 모델을 지속적으로 학습시키는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/138129806-92f49ae2-34cb-4173-8c08-750982a9ef24.png&quot; alt=&quot;image&quot; title=&quot;CT를 위한 ML 파이프라인 자동화&quot; /&gt;&lt;em&gt;CT를 위한 ML 파이프라인 자동화&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;level-1-의특징들&quot;&gt;Level 1 의 특징들&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Rapid experiment : 실험을 빠르게 반복하고, 전체 파이프라인을 프로덕션으로 빠르게 배포&lt;/li&gt;
  &lt;li&gt;개발 환경에서 쓰인 파이프라인이 운영 환경에도 그대로 쓰임. DevOps의 MLOps 통합에 있어 핵심적인 요소&lt;/li&gt;
  &lt;li&gt;포로덕션 모델의 CT(Continuous Training) : 새로운 데이터를 사용하여 프로덕션 모델이 자동으로 학습&lt;/li&gt;
  &lt;li&gt;CD: 새로운 데이터로 학습되고 검증된 모델이 지속적으로 배포됨.&lt;/li&gt;
  &lt;li&gt;Level 0에서는 학습된 모델만을 배포했다면 Level 1에서는 전체 파이프라인이 배포됨.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ct를-위해-필요한것들&quot;&gt;CT를 위해 필요한 것들&lt;/h3&gt;
&lt;p&gt;새로운 데이터를 통해 새로운 모델을 지속적으로 학습하므로, data validation과 model validation이 필수적이다.&lt;/p&gt;
&lt;h3 id=&quot;data-and-model-validation&quot;&gt;Data and Model Validation&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Data validation
데이터 검증에서 실패하면, 신규 모델의 배포를 중지해야한다. 이 의사결정도 자동화되어야 한다.
    &lt;ul&gt;
      &lt;li&gt;Data schema skews: 예상치 못한 데이터가 생성된 경우, 예상범주를 벗어난 특성이 생성된 경우 등.&lt;/li&gt;
      &lt;li&gt;Data values skews: 데이터의 통계적 속성이 변화되고 있음을 감지해야 한다. 이러한 변화를 감지해 모델의 재학습을 트리거한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Model Validation
모델이 새로운 데이터로 재학습을 마치고, 운영 환경에 반영되기 전에 평가되고 검증되어야 한다. 
    &lt;ul&gt;
      &lt;li&gt;테스트 데이터셋으로 평가 메트릭을 생성한다.&lt;/li&gt;
      &lt;li&gt;평가메트릭을 새로운 모델과, 현재 모델 사이에 비교한다. 새로운 모델이 기존 모델보다 더 나은 성과를 보이는지 검증한다.&lt;/li&gt;
      &lt;li&gt;새로운 모델의 성능이 다양한 세그먼트에서 일관된 성과를 보이는지 검증한다.&lt;/li&gt;
      &lt;li&gt;인프라 및 예측 서비스 API와 호환성 테스트를 완료한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;feature-store&quot;&gt;Feature store&lt;/h3&gt;
&lt;p&gt;Feature store는 학습과 서빙에 사용되는 모든 feature들을 모아둔 저장소이다. 대용량 배치 처리와 low latency의 실시간 서빙을 모두 지원할 수 있어야 한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;사용가능한 모든 feature의 저장소&lt;/li&gt;
  &lt;li&gt;항상 최신화된 데이터&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;metadata-management&quot;&gt;Metadata management&lt;/h3&gt;
&lt;p&gt;ML 파이프라인의 실행 정보, 데이터 및 아티팩트의 계보 등을 저장한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;실행된 파이프라인 버전, 시작-종료 시간, 소요시간 등&lt;/li&gt;
  &lt;li&gt;파이프라인의 실행자, 매개변수 인수&lt;/li&gt;
  &lt;li&gt;이전 모델에 대한 포인터(모델의 롤백이 필요한 경우)&lt;/li&gt;
  &lt;li&gt;모델 평가 단계에서 생성된 모델 평가 측정 항목.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ml-pipelinetrigger&quot;&gt;ML pipeline trigger&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;모델을 재학습 시키는 파이프라인의 자동화&lt;/li&gt;
  &lt;li&gt;매일, 매주 또는 매월 등의 재학습 빈도는 데이터 패턴의 변경 빈도와 모델 재학습 비용에 따라 달라질 수 있다.&lt;/li&gt;
  &lt;li&gt;모델 성능 저하가 눈에 띄는 경우 모델 재학습 트리거
&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;mlops-level-2-cicd-pipeline-automation&quot;&gt;MLOps level 2: CI/CD pipeline automation&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/138129823-b9b4f489-df99-44ed-9c24-8aa35d953368.png&quot; alt=&quot;image&quot; title=&quot;CI/CD and automated ML pipeline&quot; /&gt;&lt;em&gt;CI/CD and automated ML pipeline&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Google은 Level 1에서 CI/CD면에서 집중적으로 강화된 시스템을 MLOps Level 2로 구분하고 있다. CI/CD 자동화 파이프라인의 단계는 다음과 같이 보여줄 수 있다.
&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/138129840-9ee1cff5-b82e-4c3b-9694-c4e82710f944.png&quot; alt=&quot;image&quot; title=&quot;Stages of the CI/CD automated ML pipeline&quot; /&gt;&lt;em&gt;Stages of the CI/CD automated ML pipeline&lt;/em&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;continuous-integration&quot;&gt;Continuous Integration&lt;/h3&gt;
&lt;p&gt;파이프라인과 구성요소는 커밋되거나 소스 레포지토리로 푸시될 때 빌드, 테스트, 패키징된다. 아래와 같은 테스트가 포함될 수 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;특성 추출 로직을 테스트&lt;/li&gt;
  &lt;li&gt;모델에 구현된 메소드를 단위 테스트&lt;/li&gt;
  &lt;li&gt;모델 학습이 수렴하는지 테스트&lt;/li&gt;
  &lt;li&gt;모델 학습에서 0으로 나누거나 작은 값 또는 큰 값을 조작하여 NaN 값을 생성하지 않는지 테스트&lt;/li&gt;
  &lt;li&gt;파이프라인의 각 구성요소가 예상된 아티팩트를 생성하는지 테스트&lt;/li&gt;
  &lt;li&gt;파이프라인 구성요소간 통합 테스트&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;continuous-delivery&quot;&gt;Continuous Delivery&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;모델 배포 전 모델과 대상 인프라 호환성 확인. (패키지 호환 여부/메모리/컴퓨팅 자원등)&lt;/li&gt;
  &lt;li&gt;서비스 API 호출 테스트&lt;/li&gt;
  &lt;li&gt;QPS 및 지연 시간과 같은 서비스 부하 테스트&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;위 Google의 자료에서 보았듯, MLOps는 어떤 면에서 DevOps보다 더 복잡하고 많은 테스트를 필요로 하는 면도 있다. 소프트웨어의 코드 테스트 뿐만 아니라 데이터와 모델의 성능까지 테스트하고 검증해야하기 때문이다. &lt;a href=&quot;https://en.wikipedia.org/wiki/DataOps&quot;&gt;DataOps&lt;/a&gt;라는 방법론이 이미 MLOps에 디폴트로 녹아들어가져 있어야 하는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/138129859-9dc152be-8aed-46bb-a81d-8107c0a7dbb3.png&quot; alt=&quot;image&quot; title=&quot;Traditional Software System과 ML System의 테스트 차이. 근데 쫌 ML쪽만 이런저런 테스트를 더 넣은 것 같긴 한데.. 아무튼 데이터부터 테스트해야할 것이 더 많다는 이야기..! (from [애저듣보잡 MLOps 101](https://youtu.be/q2N6NZKxipg))&quot; /&gt;&lt;em&gt;Traditional Software System과 ML System의 테스트 차이. 근데 쫌 ML쪽만 이런저런 테스트를 더 넣은 것 같긴 한데.. 아무튼 데이터부터 테스트해야할 것이 더 많다는 이야기..! (from &lt;a href=&quot;https://youtu.be/q2N6NZKxipg&quot;&gt;애저듣보잡 MLOps 101&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;맺으며&quot;&gt;맺으며&lt;/h3&gt;
&lt;p&gt;엔터프라이즈 레벨에서 프로덕션 환경에 ML모델을 운영하고자 한다면 MLOps는 선택이 아닌 필수사항이 되어가고 있는 것으로 보인다.
Google에서 제시하는 모범사례까지는 안되더라도, 안정적이고 더 좋은 성능의 ML 서비스를 위해서 최대한 이를 지향점으로 삼고 구현해나가야할 것이다.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;disclaimer&quot;&gt;Disclaimer&lt;/h3&gt;
&lt;p&gt;위 글의 내용은 개인적으로 정리한 내용으로, Google의 공식 문서 및 의견과 다를 수 있습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning&quot;&gt;[Google Cloud] MLOps: Continuous delivery and automation pipelines in machine learning&lt;/a&gt; &lt;br /&gt;
&lt;a href=&quot;https://blogs.nvidia.com/blog/2020/09/03/what-is-mlops/&quot;&gt;What is MLOps?&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://youtu.be/q2N6NZKxipg&quot;&gt;[애저듣보잡] MLOps 101 | ep1. MLOps가 뭐길래&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 22 May 2021 00:00:00 +0900</pubDate>
        <link>https://jaemunbro.github.io/posts/whatis-mlops/</link>
        <guid isPermaLink="true">https://jaemunbro.github.io/posts/whatis-mlops/</guid>
        
        <category>ml</category>
        
        <category>mlops</category>
        
        
        <category>ML</category>
        
      </item>
    
      <item>
        <title>Hadoop - YARN Scheduler setting (하둡 - YARN 스케쥴러 설정)</title>
        <description>&lt;p&gt;YARN의 스케쥴러 타입에 대해 알아보기 전에 YARN에 대해서도 간단히 살펴보자.&lt;/p&gt;

&lt;h1 id=&quot;yarn&quot;&gt;YARN&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;YARN은 (Yet Another Resource Negotiator)은 하둡의 크러스터 자원관리 시스템이다. 
YARN은 클러스터의 자원을 요청하고 사용하기 위한 API를 제공한다.&lt;/p&gt;

&lt;p&gt;YARN은 리소스 매니저와 노드 매니저 두가지 장기 실행 데몬을 통해 핵심 서비스를 제공한다.
리소스 매니저는 클러스터에서 유일하며 클러스터 전체 자원의 사용량을 관리하고, 모든 머신에서 실행되는 노드 매니저는 컨테이너를 구동하고 모니터링 하는 역할을 맡는다.&lt;/p&gt;

&lt;p&gt;YARN에서 애플리케이션을 구동하는 요청 과정은 다음과 같다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;클라이언트가 애플리케이션을 구동하기 위해 리소스 매니저에 접속하여 애플리케잇녀 마스터 프로세스의 구동을 요청한다.&lt;/li&gt;
  &lt;li&gt;리소스 매니저는 컨테이너에서 애플리케이션 마스터를 구동할 수 있는 노드 매니저를 하나 찾는다.&lt;/li&gt;
  &lt;li&gt;애플리케이션 마스터가 단순한 계산을 단일 컨테이너에서 수행하고 클라이언트에 반환하고 종료하거나,&lt;/li&gt;
  &lt;li&gt;리소스 매니저에 더 많은 컨테이너를 요청한 후 분산 처리를 수행하는 경우도 있다. 4번이 맵리듀스 애플리케이션이 수행하는 방법이다.
&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/117579456-daf3fd80-b12d-11eb-8cdd-957474f7c116.png&quot; alt=&quot;image&quot; title=&quot;How YARN runs an application. from Hadoop the definitive guide&quot; /&gt;&lt;em&gt;How YARN runs an application. from Hadoop the definitive guide&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;scheduler&quot;&gt;Scheduler&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;YARN은 FIFO, Capacity, Fair Scheduler를 지원한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;FIFO는 먼저 들어온 애플리케이션을 큐에 넣고 순차대로 실행한다. 간단하고 직관적이지만 공유 클러스터 환경에서는 적합하지 않다.&lt;/li&gt;
  &lt;li&gt;Capacity Scheduler는 잡을 제출되는 즉시 분리된 전용 큐에서 처리한다. 잡을 위한 자원을 미리 예약해두므로 전체 클러스터의 효율성이 떨어질 수 있다.&lt;/li&gt;
  &lt;li&gt;Fair Scheduler는 실행 중인 모든 잡의 자원을 동적으로 분배하므로 미리 자원의 가용량을 예약해둘 필요가 없다. 대형 잡이 먼저 시작하면 모든 자원을 할당한다. 다른 잡이 중간에 들어오면 필요한 자원만큼 클러스터의 자원을 해당 잡에 나누어준다.&lt;br /&gt;
두번째 잡이 시작된 후 자원을 받을 때까지 시간은 좀 걸릴 수 있다. 첫번째 잡이 사용하고 있는 컨테이너의 자원이 해제될 때까지 기다려야하기 때문이다. 작은 잡이 완료되고 나면 대형 잡은 다시 전체 클러스터의 자원을 점유할 수 있다. 전체적으로 클러스터의 효율성도 높고 작은 잡도 빨리 처리되는 효과를 얻을 수 있다.&lt;br /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/117579463-e34c3880-b12d-11eb-9ed7-ec1a0de63508.png&quot; alt=&quot;image&quot; title=&quot;Cluster Utilization over time when running a large job and a small job under the FIFO Scheduler (i), Capacity Scheduler (ii), and Fair Scheduler (iii). from Hadoop the definitive guide&quot; /&gt;&lt;em&gt;Cluster Utilization over time when running a large job and a small job under the FIFO Scheduler (i), Capacity Scheduler (ii), and Fair Scheduler (iii).&lt;br /&gt;
from Hadoop the definitive guide&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;capacity-scheduler&quot;&gt;Capacity Scheduler&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;공유 클러스터에서 회사 내 조직마다 자원을 할당해줄 수 있다. 큐 안에는 잡이 다수 있고 가용 자원이 클러스터에 남아있다면 캐퍼시티 스케쥴러는 여분의 자원을 할당할 수도 있다. 이렇게 할당하는 경우 지정된 큐의 가용량을 초과하게 되는데, 이러한 방식을 queue elasticity라고 한다.&lt;/p&gt;

&lt;h3 id=&quot;fair-scheduler&quot;&gt;Fair Scheduler&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;페어 스케쥴러는 실행 중인 모든 애플리케이션에 동일하게 자원을 할당한다. Cloudera에서 사용을 권장하는 Scheduler 타입이다. 기본 Hadoop 스케쥴러는 Capacity Scheduler지만 CDH 배포판은 기본 스케쥴러가 Fair Scheduler이다.&lt;/p&gt;

&lt;p&gt;스케쥴러 설정은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yarn-site.xml&lt;/code&gt;에서 하고, 각 스케쥴러의 큐 설정은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;capacity-scheduler.xml&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fair-scheduler.xml&lt;/code&gt;등의 파일에서 지정한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;yarn-site.xml의 예시&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;  
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.scheduler.class&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;  
 &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;  
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;페어 스케쥴러는 클래스 경로에 있는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fair-scheduler.xml&lt;/code&gt;이라는 할당 파일에 속성을 설정한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;fair-scheduler.xml의 예시&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-xml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot;?&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;allocations&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;defaultQueueSchedulingPolicy&amp;gt;&lt;/span&gt;fair&lt;span class=&quot;nt&quot;&gt;&amp;lt;/defaultQueueSchedulingPolicy&amp;gt;&lt;/span&gt;

  &lt;span class=&quot;nt&quot;&gt;&amp;lt;queue&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;prod&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;weight&amp;gt;&lt;/span&gt;40&lt;span class=&quot;nt&quot;&gt;&amp;lt;/weight&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;schedulingPolicy&amp;gt;&lt;/span&gt;fifo&lt;span class=&quot;nt&quot;&gt;&amp;lt;/schedulingPolicy&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/queue&amp;gt;&lt;/span&gt;

  &lt;span class=&quot;nt&quot;&gt;&amp;lt;queue&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;dev&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;weight&amp;gt;&lt;/span&gt;60&lt;span class=&quot;nt&quot;&gt;&amp;lt;/weight&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;queue&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;eng&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;queue&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;science&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/queue&amp;gt;&lt;/span&gt;

  &lt;span class=&quot;nt&quot;&gt;&amp;lt;queuePlacementPolicy&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;rule&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;specified&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;create=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;false&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;rule&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;primaryGroup&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;create=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;false&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;rule&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;default&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;queue=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;dev.eng&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/queuePlacementPolicy&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/allocations&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;위 예제에서 prod 큐와 dev 큐는 40:60의 비율로 클러스터의 자원을 할당 받는다. 그리고 eng과 science 큐는 가중치를 지정하지 않았으므로 dev큐의 자원을 동등하게 할당 받는다. 가중치의 합이 정확하게 100%이 되어야할 필요는 없다. 예를 들면 예제의 prod와 dev를 각각 2, 3으로 변경해도 동일한 비율로 분배된다.&lt;br /&gt;
큐 내부의 정책은 schedulingPolicy 항목으로 재정의가 가능하다. 예를 들면 prod 큐는 가장 빨리 끝나는게 중요하므로 내부적으로 FIFO를 적용했다.&lt;/p&gt;

&lt;h4 id=&quot;preemption-선점&quot;&gt;&lt;strong&gt;Preemption (선점)&lt;/strong&gt;&lt;/h4&gt;
&lt;hr /&gt;
&lt;p&gt;클러스터가 꽉 차게 수행되고 있는 상태에서 Fair Scheduler 모드로 새로 제출된 잡은 다른 잡이 자원을 해제해주기 전까지 잡을 시작할 수 없다. 잡의 시작 시간을 어느 정도 예측가능하게 해주기 위해 선점 기능을 세팅할 수 있다. 선점은 스케쥴러가 자원의 균등 공유에 위배되는 큐에서 실행되는 컨테이너를 ‘죽일’ 수 있도록 허용한다. 이렇게 수행되다가 중간에 죽은 컨테이너는 결국 다시 처음부터 수행되어야 하므로 클러스터의 효율은 떨어질 수 있다.&lt;br /&gt;
선점은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yarn.scheduler.fair.preemption&lt;/code&gt;을 true로 설정하여 활성화 시킬 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;delay-scheduling&quot;&gt;Delay Scheduling&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;YARN의 모든 스케쥴러는 지역성을 가장 우선시한다. 어떤 애플리케이션이 특정 노드를 요청하면 딱 그 시점에는 그 노드가 바쁠 가능성이 높다. 이 경우 지역성을 조금 포기해서 동일 노드가 아니라 동을 랙에 컨테이너를 할당할 수도 있다. 하지만 대부분의 경우 ‘조금만’ 기다리면 요청한 노드에서 컨테이너를 할당받을 수 있는 기회가 크게 증가한다. 이러한 기능을 지연 스케쥴링(delay scheduling)이라고 한다.&lt;/p&gt;

&lt;h4 id=&quot;aws-emr에서-scheduler-설정-변경&quot;&gt;AWS EMR에서 Scheduler 설정 변경&lt;/h4&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/premiumsupport/knowledge-center/restart-service-emr/&quot;&gt;https://aws.amazon.com/premiumsupport/knowledge-center/restart-service-emr/&lt;/a&gt;
&lt;a href=&quot;https://stackoverflow.com/questions/34953319/how-to-restart-yarn-on-aws-emr/&quot;&gt;https://stackoverflow.com/questions/34953319/how-to-restart-yarn-on-aws-emr/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;
&lt;p&gt;Tom White, Hadoop The Definitive Guide(하둡 완벽가이드 4판, 2018), 한빛미디어
&lt;a href=&quot;https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/admin_fair_scheduler.html&quot;&gt;https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/admin_fair_scheduler.html&lt;/a&gt;
&lt;a href=&quot;https://wikidocs.net/book/2203&quot;&gt;https://wikidocs.net/book/2203&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 09 May 2021 11:45:00 +0900</pubDate>
        <link>https://jaemunbro.github.io/posts/yarn-scheduler/</link>
        <guid isPermaLink="true">https://jaemunbro.github.io/posts/yarn-scheduler/</guid>
        
        <category>hadoop</category>
        
        <category>yarn</category>
        
        <category>scheduler</category>
        
        
        <category>Hadoop</category>
        
      </item>
    
      <item>
        <title>Spark - Core Optimization (스파크 - 최적화)</title>
        <description>&lt;p&gt;스파크의 기본적인 최적화 세팅 방법들에 대해 정리해보자.
본문 작성에 주되게 참조한 소스는 Spark + AI Summit Europe 2019에서 발표한 Databricks의 Daniel Tomes의 세션인 &lt;a href=&quot;https://databricks.com/session_eu19/apache-spark-core-practical-optimization&quot;&gt;Apache Spark Core – Practical Optimization&lt;/a&gt;이다.&lt;/p&gt;

&lt;h1 id=&quot;general-optimization&quot;&gt;General Optimization&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;Practical Optimization에 관해서 깊이 파보기 전에, 기본적인 최적화 방법들에 대해서 먼저 간단히 살펴보자.&lt;/p&gt;

&lt;h3 id=&quot;file-format-최적화&quot;&gt;File Format 최적화&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Parquet, ORC와 같은 columnar file 활용&lt;/li&gt;
  &lt;li&gt;splittable file format 사용 (snappy, bzip2와 같은 compression format)&lt;/li&gt;
  &lt;li&gt;너무 많은 small file은 compaction 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;parallelism&quot;&gt;Parallelism&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;데이터 사이즈에 맞춘 스파크 파티션 생성. 너무 적은 파티션 수는 executor를 idle하게 만들 수 있고 반대로 너무 많은 파티션은 task scheduling 오버헤드를 지나치게 높게 만들 수 있다.&lt;/li&gt;
  &lt;li&gt;executor 최소한 2-3개 이상의 코어를 할당&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.shuffle.partitions&lt;/code&gt; 기본값 200은 빅데이터 프로덕션 환경에서는 너무 작으므로 기본적으로 튜닝이 필요하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;shuffle-줄이기&quot;&gt;Shuffle 줄이기&lt;/h3&gt;
&lt;p&gt;shuffle은 네트워크와 disk I/O를 포함하는 노드간 데이터 이동을 불러일으키는 가장 비싼 연산이다. shuffle을 줄이는 것이 튜닝의 시작이다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.shuffle.partitions&lt;/code&gt;을 튜닝한다.&lt;/li&gt;
  &lt;li&gt;각 task 사이즈가 너무 저지지 않도록 input data를 파티셔닝한다.&lt;/li&gt;
  &lt;li&gt;일반적으로, 파티션당 100MB에서 200MB 사이를 타게팅하도록 한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.shuffle.partitions&lt;/code&gt; = (shuffle stage input size/target size)/total cores) * total cores&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;filterreduce-dataset-size&quot;&gt;Filter/Reduce dataSet size&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;partition된 데이터를 활용한다.&lt;/li&gt;
  &lt;li&gt;최대한 이른 stage에서 데이터를 filter out 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;적절한-cache-사용&quot;&gt;적절한 Cache 사용&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;pipeline에서 여러번 계산이 필요한 df에서 활용한다.&lt;/li&gt;
  &lt;li&gt;unpersist를 하자.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;join&quot;&gt;Join&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;BroadcastHashJoin을 최대한 활용하자. 가장 성능이 빠른 Join이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cluster-리소스-튜닝&quot;&gt;Cluster 리소스 튜닝&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;spark.driver.memory, executor-memory, num-executors, and executor-cores 튜닝&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;비싼-연산은-피하자&quot;&gt;비싼 연산은 피하자&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;order by는 필수적인 경우만 쓴다.&lt;/li&gt;
  &lt;li&gt;모든 컬럼을 선택하기 위한 (*)는 지양하고, 필요한 컬럼을 선택해서 쓴다.&lt;/li&gt;
  &lt;li&gt;count()도 꼭 필요한 경우에만.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;skew--아래-advanced-optimization-참조&quot;&gt;Skew  (아래 Advanced Optimization 참조)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;salting 통해 해결&lt;/li&gt;
  &lt;li&gt;partition이 불균형한 경우, 균형잡힌 파티션을 재생성하기 위해 repartition을 하고 cache해두는 것을 고려해볼 수도 있다&lt;/li&gt;
  &lt;li&gt;Spark 3.0을 쓴다..ㅎ&lt;/li&gt;
  &lt;li&gt;SparkUI에서 partition size와 task duration을 확인하자&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;udf&quot;&gt;UDF&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;UDF 사용은 최대한 지양한다. (아래 Advanced Optimization 참조)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;practical-optimization&quot;&gt;Practical Optimization&lt;/h1&gt;
&lt;h2 id=&quot;하드웨어-스펙에-대한-이해&quot;&gt;하드웨어 스펙에 대한 이해&lt;/h2&gt;
&lt;hr /&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Core Count &amp;amp; Speed&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Memory Per Core&lt;/strong&gt; (메모리당 코어가 얼마나 되는가)&lt;/li&gt;
  &lt;li&gt;local disk type, count, size, speed&lt;/li&gt;
  &lt;li&gt;network speed, toplology&lt;/li&gt;
  &lt;li&gt;cost / core / hour&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;get-a-baseline&quot;&gt;Get A Baseline&lt;/h2&gt;
&lt;hr /&gt;
&lt;ul&gt;
  &lt;li&gt;Is your action efficient?
    &lt;ul&gt;
      &lt;li&gt;Long Stages, Spills, Laggard Tasks&lt;br /&gt;
  duration으로 sorting해서 가장 오래 돌고 있는 Stage를 파악하는 것부터 시작할 수 있다.&lt;br /&gt;
  disk spill이 심하게 일어나고 있는 Stage인 경우를 찾는다. 보통 가장 오래 도는 Job과 동일한 경우가 많다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;CPU Utilization
    &lt;ul&gt;
      &lt;li&gt;Ganglia / Yarn&lt;br /&gt;
  CPU 활용률이 너무 낮다면, CPU 활용률이 70% 내외로 활용될 수 있도록 타겟으로 잡아볼 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;데이터-스캔-최소화---minimize-data-scans&quot;&gt;데이터 스캔 최소화 - Minimize Data Scans&lt;/h2&gt;
&lt;hr /&gt;
&lt;ul&gt;
  &lt;li&gt;가장 간단하지만 가장 중요한 최적화 기법&lt;br /&gt;
&lt;strong&gt;Lazy loading&lt;/strong&gt; - 데이터를 파티셔닝을 최대한 필터하고 로딩해서 사용한다.&lt;/li&gt;
  &lt;li&gt;Hive Partition&lt;br /&gt;
&lt;strong&gt;Partition pruning&lt;/strong&gt;을 통한 스캔 대상 데이터 최소화&lt;/li&gt;
  &lt;li&gt;Bucketing (Only for experts - 제대로 유지하는 것이 거의 불가능에 가까움..)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;spark-partitions---inputshuffleoutput&quot;&gt;Spark Partitions - Input/Shuffle/Output&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;스파크 파티션을 컨트롤하는 두가지 핵심은&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Spill을 피하도록 한다&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;최대한의 Core를 활용할 수 있도록 한다&lt;/strong&gt;
이다. 데이터의 Input 단계부터 Shuffle 단계, Output 단계로 나눠서 알아보자.
    &lt;h4 id=&quot;1-input&quot;&gt;(1) Input&lt;/h4&gt;
    &lt;ul&gt;
      &lt;li&gt;Size를 컨트롤한다.&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.file.maxPartitionBytes&lt;/code&gt; default value : 128MB&lt;/li&gt;
    &lt;/ul&gt;
    &lt;ul&gt;
      &lt;li&gt;Increase Parallelism: 코어의 활용률을 병렬도를 더 올리기 위해 쪼개서 읽을 수 있다. 
 예시)
 &lt;img src=&quot;https://user-images.githubusercontent.com/29077671/116790207-11a69400-aaee-11eb-8b26-79e65539e52c.png&quot; alt=&quot;image&quot; /&gt;
 shuffle이 없는 map job이므로 오직 read/write 속도에만 dependant한 task인데, 더 빠르게 처리하기 위해 maxPartitionSize를 core 수에 맞게 튜닝했고 그것만으로 시간을 50% 줄일 수 있었다. 더 많은 코어가 나누어서 처리했기 때문이다.&lt;/li&gt;
      &lt;li&gt;Heavily Nested/Repetitive Data: 메모리에서 풀어냈을때 데이터가 커질 수 있으므로 더 작게 읽는 것이 필요할 수도 있다.&lt;/li&gt;
      &lt;li&gt;Generating Data - Explode: 이 역시 새로운 데이터 컬럼을 만들면서 데이터가 메모리 상에서 커질 수 있으므로.&lt;/li&gt;
      &lt;li&gt;Source Structure is not optimal(upstream)&lt;/li&gt;
      &lt;li&gt;UDFs&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;2-shuffle&quot;&gt;(2) Shuffle&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Count를 컨트롤한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.shuffle.partitions&lt;/code&gt; default value : 200&lt;/li&gt;
  &lt;li&gt;가장 큰 셔플 스테이지의 타겟 사이즈를 파티션당 200MB 이하로 잡는 것이 적절하다. &lt;br /&gt;
(target size &amp;lt;= 200 MB/partition)
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;예시를 들어보자.
  Shuffle Stage Input = 210GB&lt;br /&gt;
  210000MB / 200MB = 1050
  -&amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.conf.set(&quot;spark.sql.shuffle.partitions&quot;, 1050)&lt;/code&gt;&lt;br /&gt;
  하지만 만약 클러스터의 가용 코어가 2000 이라면 다 활용하면 더 좋다.&lt;br /&gt;
  -&amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.conf.set(&quot;spark.sql.shuffle.partitions&quot;, 2000)&lt;/code&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;또 다른 예시 - spark history server의 stage 모니터링
  &lt;img src=&quot;https://user-images.githubusercontent.com/29077671/116789923-7c56d000-aaec-11eb-9fc7-0e7b1fcbe557.png&quot; alt=&quot;image&quot; /&gt;
  위 예시의 우측 Summary Metrics를 보면 Median 값이 270MB이다. 아주 나쁘진 않지만 그래도 파티션이 부족하다고 봐야한다.
  위의 예시에서 stage 19와 stage 20이 stage 21의 셔플의 소스이므로, 19와 20의 shuffle write이 21의 shuffle input이 라고 볼 수 있다.
  간단하게 이야기해서, shuffle spill(memory/disk)가 일어나고 있다면 파티션이 더 필요하다고 이해해도 좋다.&lt;/li&gt;
      &lt;li&gt;partition count = stage input data / target size&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;3-output&quot;&gt;(3) Output&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Count를 컨트롤한다.&lt;/li&gt;
  &lt;li&gt;coalesce(n) : 2000개의 partition이 shuffle하고 나서, write할 때 100개가 나눠서 할 수 있도록.&lt;/li&gt;
  &lt;li&gt;Repartition(n) : partition을 증가시킬 때 사용. shuffle을 발생시키므로 꼭 필요한 경우가 아니면 사용하지 말자.&lt;/li&gt;
  &lt;li&gt;df.write.option(“maxRecordsPerFile”, N) : 추천하는 방법은 아님.
&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/116790347-998c9e00-aaee-11eb-85be-baf026979fc3.png&quot; alt=&quot;image&quot; /&gt;
전체 160GB의 파일을 처리하는데 10개의 코어가 1.6GB씩 처리할 때와 100개의 코어가 처리할 때의 차이는 아주 크다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;skew-join-optimization&quot;&gt;Skew Join Optimization&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;어떤 파티션이 다른 파티션보다 훨씬 큰 경우.
예시) 어떤 키 하나에는 수백만개의 count가 몰려 있고, 나머지 키에는 수십개 정도씩만 있다고 가정하자.
&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/116791009-85e33680-aaf2-11eb-9ba1-a4cd5196d7b2.png&quot; alt=&quot;image&quot; /&gt;
&lt;strong&gt;Salting&lt;/strong&gt;이라 불리는 방법을 통해 해결해볼 수 있다. 노이즈 데이터를 뿌려넣는다는 의미이다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;0부터 spark.sql.suffle.partitoins - 1 사이의 random int값을 가진 column을 양쪽 데이터프레임에 생성한다.&lt;/li&gt;
  &lt;li&gt;Join 조건에 새로운 salting column을 포함한다.&lt;/li&gt;
  &lt;li&gt;result 표출 시 salting column을 drop한다.
    &lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nv&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;groupBy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;city&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;state&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&amp;lt;&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&amp;gt;).&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;orderBy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;co&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;saltVal&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;withColumn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;salt&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;saltVal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;groupBy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;city&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;state&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;salt&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;agg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&amp;lt;&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&amp;gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;salt&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;orderBy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;py&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Spark3.0부터는 join 시 동적으로 splitting - replicating등의 작업을 통해 재분배하는 조건이 생겼다.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.adaptive.skewJoin.enabled&lt;/code&gt;  default: true
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.adaptive.skewJoin.skewedPartitionFactor&lt;/code&gt;  default: 10
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes&lt;/code&gt;  default 256MB&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;minimize-data-scans-persistence&quot;&gt;Minimize Data Scans (Persistence)&lt;/h2&gt;
&lt;hr /&gt;
&lt;ul&gt;
  &lt;li&gt;Persistence는 무료가 아니다.&lt;/li&gt;
  &lt;li&gt;반복작업이 있는 경우에 사용한다.&lt;/li&gt;
  &lt;li&gt;기본 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;df.cache == df.persist(StorageLevel.MEMORY_AND_DISK)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;다른 타입들의 장단점에 대해서도 알아보자.
    &lt;ul&gt;
      &lt;li&gt;Default StorageLevel.MEMORY_AND_DISK&lt;br /&gt;
  (deserialized)&lt;/li&gt;
      &lt;li&gt;deserialized = Faster = Bigger&lt;/li&gt;
      &lt;li&gt;serialized = Slower = Smaller&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;df.unpersist 를 잊지말자!!&lt;/strong&gt;&lt;br /&gt;
cache memory를 사용하는 만큼 working memory가 줄어들 것이므로.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;join-optimization&quot;&gt;Join Optimization&lt;/h2&gt;
&lt;hr /&gt;
&lt;ul&gt;
  &lt;li&gt;SortMerge Join : 양쪽 데이터가 다 클 때&lt;/li&gt;
  &lt;li&gt;Broadcast Join : 한쪽 데이터가 작을때
    &lt;ul&gt;
      &lt;li&gt;옵티마이저에 의해 자동으로 활성화됨 (one side &amp;lt; spark.sql.autoBroadcastJoinThreshold) 기본값은 10M.&lt;/li&gt;
      &lt;li&gt;Risk
        &lt;ul&gt;
          &lt;li&gt;Not Enough Driver Memory&lt;/li&gt;
          &lt;li&gt;DF &amp;gt; spark.driver.maxResultSize&lt;/li&gt;
          &lt;li&gt;DF &amp;gt; single executor available working memory&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/116790846-8a5b1f80-aaf1-11eb-9ccf-f82a30430e94.png&quot; alt=&quot;image&quot; /&gt;
        &lt;ul&gt;
          &lt;li&gt;broadcast join을 조심해야하는 이유 : driver에서 hashmap format datafame으로 바꿔서 각 executor로 보낸다. hashmap을 만들면서 기존에 compression이 되어 있던 것도 풀리므로 데이터 사이즈도 처음 partition 안에 있을 때보다 몇배 커진 상태가 될 수 있다. (e.g., 126MB -&amp;gt; 270MB)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;broadcastnestedloopjoin-bnlj&quot;&gt;BroadcastNestedLoopJoin (BNLJ)&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;SparkSQL에서는 NOT IN 조건 대신 NOT EXISTS를 사용하라. 훨씬 효율적이다.
&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/116791238-db6c1300-aaf3-11eb-854b-fe73059567b4.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;비싼-오퍼레이션을-제외시키자---omit-expensive-ops&quot;&gt;비싼 오퍼레이션을 제외시키자 - Omit Expensive Ops&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;튜닝의 시작을 IntelliJ에서 아래 키워드들을 찾는 것부터 해볼 수도 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Repartition&lt;br /&gt;
coalesce를 쓰거나 shuffle partition count 세팅을 바꿔서 써라.&lt;/li&gt;
  &lt;li&gt;count()&lt;br /&gt;
진짜 필요한 경우에만 써라.&lt;br /&gt;
습관적으로 많이 쓰긴 하지만, 프로덕션 배포 전에 제외시키는 걸 잊지 말자!&lt;/li&gt;
  &lt;li&gt;distinctCount
-&amp;gt; 꼭 정확한 숫자가 필요한 것이 아니라면 가능하면 approxCountDistinct()를 써라.&lt;br /&gt;
생각해보면 2% 내외의 오차가 발생하는 것을 감수할 수 있는 경우가 많다.&lt;/li&gt;
  &lt;li&gt;distinct
    &lt;ul&gt;
      &lt;li&gt;distinct 대신 dropDuplicates을 써라.&lt;/li&gt;
      &lt;li&gt;dropDuplicates를 JOIN 전에 써라.&lt;/li&gt;
      &lt;li&gt;dropDuplicates를 groupBy 전에 써라.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;udf-penalties&quot;&gt;UDF penalties&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;UDF 사용은 최대한 피하는게 좋다.&lt;/li&gt;
  &lt;li&gt;일반적으로 scala udf가 python udf보다 빠르다. r udf는 가~끔 작동한다.&lt;/li&gt;
  &lt;li&gt;org.apache.spark.sql.functions를 최대한 활용하자.&lt;/li&gt;
  &lt;li&gt;UDF 만들기 전에 PandasUDF(vectorized UDFs)에 원하는 기능이 없는지 알아보자.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;advanced-parallelism&quot;&gt;Advanced Parallelism&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Driver Parallelism&lt;br /&gt;
델타 처리를 위한 예시. executor로 넘기기 전에 driver부터 multi thread로 일할 수 있도록 해준다. &lt;br /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/116791534-0f483800-aaf6-11eb-9cd8-fd0d86925c62.png&quot; alt=&quot;image&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;Horizontal Parallelsim&lt;/li&gt;
  &lt;li&gt;Executor Parallelism&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;더-알아보기-좋은-글&quot;&gt;더 알아보기 좋은 글&lt;/h4&gt;
&lt;p&gt;GC tuning: &lt;a href=&quot;https://databricks.com/blog/2015/05/28/tuning-java-garbage-collection-for-spark-applications.html&quot;&gt;https://databricks.com/blog/2015/05/28/tuning-java-garbage-collection-for-spark-applications.html&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://databricks.com/session_eu19/apache-spark-core-practical-optimization&quot;&gt;https://databricks.com/session_eu19/apache-spark-core-practical-optimization&lt;/a&gt;
&lt;a href=&quot;https://developer.ibm.com/technologies/artificial-intelligence/
blogs/spark-performance-optimization-guidelines/&quot;&gt;https://developer.ibm.com/technologies/artificial-intelligence/blogs/spark-performance-optimization-guidelines/&lt;/a&gt;
&lt;a href=&quot;https://spark.apache.org/docs/latest/sql-performance-tuning.html&quot;&gt;https://spark.apache.org/docs/latest/sql-performance-tuning.html&lt;/a&gt;
&lt;a href=&quot;https://spark.apache.org/docs/latest/tuning.html&quot;&gt;https://spark.apache.org/docs/latest/tuning.html&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 01 May 2021 01:43:00 +0900</pubDate>
        <link>https://jaemunbro.github.io/posts/spark-basic-optimization/</link>
        <guid isPermaLink="true">https://jaemunbro.github.io/posts/spark-basic-optimization/</guid>
        
        <category>spark</category>
        
        <category>optimization</category>
        
        
        <category>Spark</category>
        
      </item>
    
      <item>
        <title>Spark - Troubleshooting Cheatsheet (스파크 - 트러블슈팅 가이드)</title>
        <description>&lt;p&gt;스파크의 문제 사례들과 그 해결 방법들에 대해 알아보자.&lt;br /&gt;
문제 케이스들은 일부 직접 겪은 것들과 본문 하단 링크의 케이스들을 취합하였다.&lt;/p&gt;

&lt;h1 id=&quot;troubleshooting-tips&quot;&gt;Troubleshooting Tips&lt;/h1&gt;
&lt;h3 id=&quot;트러블슈팅을-위해-verbose-mode를-활용하자&quot;&gt;트러블슈팅을 위해 verbose mode를 활용하자&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark-submit --driver-memory 10g --verbose --master yarn --executor memory...&lt;/code&gt;&lt;br /&gt;
다음 정보들이 프린트된다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;all default properties&lt;/li&gt;
  &lt;li&gt;command line options&lt;/li&gt;
  &lt;li&gt;setting from spark ‘conf’ file&lt;/li&gt;
  &lt;li&gt;setting from CLI&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;executor-thread--heap-dump&quot;&gt;executor thread &amp;amp; heap dump&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jmap, jstack, jstat, jhat&lt;/code&gt;과 같은 OpenJDK 툴을 통해 executor의 thread dump나 heap dump를 떠볼 수 있다.
YARN 컨테이너의 pid를 찾아서 사용한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;for full thread dump
    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;jstack &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt; 355583 &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; javacore.355583
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;for full heap dump
    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;jmap &lt;span class=&quot;nt&quot;&gt;-dump&lt;/span&gt;:live,format&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;b,file&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;heapdump.355583 355583 
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;error-cases&quot;&gt;Error Cases&lt;/h1&gt;
&lt;hr /&gt;
&lt;h3 id=&quot;compiled-ok-but-run-time-noclassdeffounderror&quot;&gt;Compiled OK, but run-time NoClassDefFoundError&lt;/h3&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nl&quot;&gt;NoClassDefFoundError:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thread&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;main&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;NoClassDefFoundError&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kafka&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clients&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;KafkaProducer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getDeclaredMethods0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Native&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;privateGetDeclaredMethods&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2701&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;privateGetMethodRecursive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3048&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getMethod0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3018&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--packages&lt;/code&gt; 를 통해 Maven Jar 포함
e.g.)&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;submit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;master&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yarn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;executor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4096&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;executors&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;packages&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;streaming&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kafka_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;repo look up 순서
    &lt;ol&gt;
      &lt;li&gt;local Maven repo - local machine&lt;/li&gt;
      &lt;li&gt;Maven centoral - Web&lt;/li&gt;
      &lt;li&gt;Additional remote repositories specified in - repositories&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;no-space-left-on-device&quot;&gt;No space left on device&lt;/h3&gt;
&lt;hr /&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;89.3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;failed&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;times&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;most&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;failure:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Lost&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;38.4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;89.3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;TID&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rhel4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;cisco&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;IOException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;No&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;space&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;FileOutputStream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;writeBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Native&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;FileOutputStream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FileOutputStream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;326&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;TimeTrackingOutputStream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TimeTrackingOutputStream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;58&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;BufferedOutputStream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;flushBuffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;BufferedOutputStream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;82&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;BufferedOutputStream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;BufferedOutputStream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;126&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;얼마전 운영중인 클러스터에서 발생했던 에러다.&lt;br /&gt;
스파크가 map output file들과 RDD를 저장해두는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/tmp&lt;/code&gt;가 꽉찬 경우다. 일단은 cron에 정기적으로 tmp 정리를 통해 해결했다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.local.dir&lt;/code&gt; 파라미터값의 디폴트값이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/tmp&lt;/code&gt;인데, 근본적으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/tmp&lt;/code&gt;를 Spark의 scratch 공간으로 두는 것 자체가 적절치 않다. 아래 두가지 이유 때문인데
    &lt;ol&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/tmp&lt;/code&gt;는 일반적으로 작은 공간이 할당되며 OS를 위한 공간이다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/tmp&lt;/code&gt;는 보통 single disk로 IO bottleneck의 원인이 될 수 있다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark-defualts.conf&lt;/code&gt;에 아래와 같은 내용을 추가하자.&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.local.dir /data/disk1/tmp,/data/disk2/tmp,/data/disk3/tmp,/data/disk4/tmp,...&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;brodcasttimeout-error&quot;&gt;BrodcastTimeout Error&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;역시 최근 클러스터에서 발생했는데, 명확하게 BroadcastTimeout Error라고 떨어지는 경우도 있지만, surface상에는 Catalyst error로 떨어지는 경우도 있는 것 같다.&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt; &lt;span class=&quot;nc&quot;&gt;Typical&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stream7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query_07_24_48&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;Error:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;catalyst&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;package&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$TreeNodeException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;tree:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;execution&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;exchange&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ShuffleExchange&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$anonfun$doExecute&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ShuffleExchange&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;122&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;execution&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;exchange&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ShuffleExchange&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$anonfun$doExecute&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ShuffleExchange&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;113&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;catalyst&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;package&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;attachTree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;package&lt;/span&gt;&lt;span class=&quot;nn&quot;&gt;.scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;49&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;96&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;more&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Caused&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;by:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;util&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;concurrent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;TimeoutException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Futures&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timed&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;after&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;concurrent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;impl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$DefaultPromise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ready&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;219&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;concurrent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;impl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$DefaultPromise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;223&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;concurrent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$anonfun$result&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;package&lt;/span&gt;&lt;span class=&quot;nn&quot;&gt;.scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;190&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;concurrent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;BlockContext&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$DefaultBlockContext&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;blockOn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;BlockContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;53&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;concurrent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;package&lt;/span&gt;&lt;span class=&quot;nn&quot;&gt;.scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;190&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;util&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ThreadUtils&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;awaitResult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ThreadUtils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;190&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;208&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;more&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;§ &lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;On&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;surface&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;appears&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;be&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Catalyst&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; 
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.broadcastTimeout 1200&lt;/code&gt; 처럼 parameter를 늘려주는 설정을 통해 해결한다. 
broadcast하는 size의 limit이 있으므로, 무제한으로 broadcast 되지는 않을 것이라 보았다. 클러스터에서 수행되는 긴 쿼리 기준으로 세팅할 수 있을 것이다.&lt;/p&gt;

&lt;h2 id=&quot;out-of-memory-exceptions&quot;&gt;Out of Memory Exceptions&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;Spark Job이 Executor 또는 Driver의 out of memory exception으로 인해 실패했을 수 있다.
일반적으로는 Executor의 메모리가 부족한 상황을 많이 만나게 된다. 
Executor의 사이즈를 늘려주는 방법을 통해 해결할 수도 있지만, 근본적으로는 애플리케이션이 얼마나 많은 메모리를 필요로 하는지 이해할 수 있어야 한다. 이 부분은 스파크 애플리케이션 최적화에 있어서 가장 기본적이고 필수적인 파라미터 부분이므로 반드시 알아두는 것이 좋다.&lt;br /&gt;
아래 부터 Driver와 Executor의 메모리 에러 상황들에 대해서 더 알아보자.&lt;/p&gt;

&lt;h2 id=&quot;driver-memory-exceptions&quot;&gt;Driver Memory Exceptions&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;드라이버 메모리가 부족한 경우는 보통 (휴먼 에러가 아니라면) &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--driver-memory&lt;/code&gt; 설정을 통해 해결한다. Default값인 512M는 일반적으로 운영환경에서는 너무 작은 값이다.&lt;br /&gt;
&lt;strong&gt;Spark SQL과 Spark Strmeaing은 일반적으로 큰 driver heap size를 요구하는 spark job의 형태&lt;/strong&gt;다.&lt;/p&gt;

&lt;h3 id=&quot;exception-due-to-spark-driver-running-out-of-memory&quot;&gt;Exception due to Spark driver running out of memory&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;명시적으로 collect() action 등의 driver memory를 사용하지 않는데, driver memory exception이 나서 의아했던 적이 있다. Spark SQL의 Optimizer가 relation을 broadcasting 하기 위해서 중간 과정으로 필요할 수 있다.
드라이버 메모리가 부족한 경우 아래와 같은 형태의 메시지를 볼 수 있다.&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thread&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;broadcast-exchange-0&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;OutOfMemoryError&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enough&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;broadcast&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;worker&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;As&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;workaround&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;you&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;can&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;either&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;broadcast&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;setting&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;autoBroadcastJoinThreshold&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;increase&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;setting&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;memory&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;higher&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;에러 메시지 상 workaround를 제시된대로, 해당 job에 대해서 브로드캐스트 조인을 끄거나, 브로드캐스트 조인의 threshold를 낮추는 것을 고려할 수도 있다. 아니면 드라이버 메모리의 세팅을 늘려줘서 해결할 수 있다. 
메모리가 허용한다면 당연히 후자가 좋을 것이다. 
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--conf spark.driver.memory= &amp;lt;XX&amp;gt;g&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;job-failure-because-the-application-master-that-launches-the-driver-exceeds-memory-limits&quot;&gt;Job failure because the Application Master that launches the driver exceeds memory limits&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;Application Master(AM)이 드라이버를 메모리 리밋을 넘겨서 런칭했고 YARN에 의해 terminated된 경우.&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nl&quot;&gt;Diagnostics:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Container&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;XXXXX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;containerID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;container_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;XXXXXXXXXX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;XXXX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;XX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;XXXXXX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;running&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beyond&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;physical&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;limits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;Current&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;usage:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;XX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;GB&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;XX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;GB&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;physical&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;used&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;XX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;GB&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;XX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;GB&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;virtual&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;used&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Killing&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;container&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;executor-memory-exceptions&quot;&gt;Executor Memory Exceptions&lt;/h2&gt;
&lt;h3 id=&quot;exception-because-executor-runs-out-of-memory&quot;&gt;Exception because executor runs out of memory&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;스파크 운영 중 종종 마주치게 되는 전형적인 GC issue.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;garbage collection에 98% 이상의 total time이 쓰여지고 있는 경우&lt;/li&gt;
  &lt;li&gt;gc를 통해 2% 이하의 heap이 회복된 경우&lt;/li&gt;
  &lt;li&gt;top command를 통해 확인했을 때, 1 cpu core가 100% 사용률을 치고 있는데 완료되고 있는 job은 없는 경우
    &lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nc&quot;&gt;Executor&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;launch&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;worker&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;XXXXXX&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ERROR&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;Executor:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;XX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;TID&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;XXXXXX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;OutOfMemoryError&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;GC&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;overhead&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exceeded&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Executor의 사이즈를 늘려주는 방법을 통해 해결한다.&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--conf spark.executor.memory= &amp;lt;XX&amp;gt;g&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GC policy를 변경한다.&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Spark default는 -XX:UseParallelGC&lt;/li&gt;
      &lt;li&gt;-XX:G1GC 로 overwrite을 시도해볼 수 있다.&lt;/li&gt;
      &lt;li&gt;Default가 일반적으로 좋지만, 상황에 따라 다를 수 있다. (자세한 내용은 별도의 포스트에서 다루고자 한다)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;fetchfailedexception-due-to-executor-running-out-of-memory&quot;&gt;FetchFailedException due to executor running out of memory&lt;/h3&gt;
&lt;hr /&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nc&quot;&gt;ShuffleMapStage&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;XX&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SqlWrapper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;XX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;failed&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;XXX&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;due&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;FetchFailedException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;failed&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;allocate&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;XXXXX&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;byte&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;direct&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;memory&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;used:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;XXXXX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;max:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;XXXXX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;Copy&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clipboard&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;executor 메모리를 더 늘려주거나,
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--conf spark.executor.memory= &amp;lt;XX&amp;gt;g&lt;/code&gt;
shuffle partition의 수를 더 늘려줄 수 있다.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--spark.sql.shuffle.partitions&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;executor-container-killed-by-yarn-for-exceeding-memory-limits&quot;&gt;Executor container killed by YARN for exceeding memory limits&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;Executor를 호스닝하는 container가 overhead task나 executor task를 위해서 더 많은 메모리를 필요로 하는 경우 아래와 같은 에러가 발생할 수 있다.&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;SparkException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Job&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aborted&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;due&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;failure:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Task&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;failed&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;times&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;most&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;failure:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Lost&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;TID&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;XX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;XX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;XX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;XXX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;executor&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExecutorLostFailure&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;executor&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exited&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caused&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;one&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;running&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;Reason:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Container&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;killed&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;YARN&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exceeding&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;limits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;XX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;GB&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;XX&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;GB&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;physical&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;used&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Consider&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boosting&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;yarn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;executor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;memoryOverhead&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;executor의 memory overhead 비중을 더 높게 세팅해줄 수 있다.
executor의 메모리 오버헤드 사이즈는 executor의 사이즈에 비례해서 커진다.(대략 6-10%)
best practice는 executor size에 맞춰서 memory overhead size도 조정해주는 것이다.&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--conf spark.executor.memoryOverhead=XXXX&lt;/code&gt;&lt;br /&gt;
위의 방법이 통하지 않는다면, 더 큰 인스턴스로 옮기거나, 코어의 개수를 줄여볼 수도 있다.&lt;br /&gt;
코어의 개수를 줄이면 메모리가 낭비되겠지만, job은 일단 돌릴 수 있을 것이다.&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--executor-cores=XX&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;filealreadyexistsexception&quot;&gt;FileAlreadyExistsException&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;이전에 실패한 task에서 파일들을 남겨서 FileAlreadyExistsException를 발생시킬 수 있다.
executor가 메모리 부족으로 실패하고 다른 executor가 다시 해당 task를 이어받았을 때 발생할 수 있다.
어떤 Spark executor가 실패했을 때, Maximum number만큼 retry하고 나서 이 Exception을 남길 수 있다.&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;SparkException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Task&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;failed&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;writing&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rows&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;execution&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;datasources&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;FileFormatWriter&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$apache$spark$sql$execution$datasources$FileFormatWriter&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$executeTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FileFormatWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;272&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;execution&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;datasources&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;FileFormatWriter&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$anonfun$write&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$anonfun$apply$mcV$sp&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FileFormatWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;191&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;execution&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;datasources&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;FileFormatWriter&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$anonfun$write&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$anonfun$apply$mcV$sp&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FileFormatWriter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;190&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scheduler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ResultTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;runTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ResultTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;87&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scheduler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Task&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;108&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;executor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;Executor&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$TaskRunner&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Executor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;335&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;util&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;concurrent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ThreadPoolExecutor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;runWorker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ThreadPoolExecutor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1142&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;util&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;concurrent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ThreadPoolExecutor&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$Worker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ThreadPoolExecutor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;617&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;more&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;Caused&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;by:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;FileAlreadyExistsException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;s3:&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;//xxxxxx/xxxxxxx/xxxxxx/analysis-results/datasets/model=361/dataset=encoded_unified/dataset_version=vvvvv.snappy.parquet already exists&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;s3a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;S3AFileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;S3AFileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;806&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hadoop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;FileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FileSystem&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;java&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;914&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;FileAlreadyExistsException의 root cause인, 가장 앞서 실패한 original executor의 실패 원인을 밝힌다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;max-result-size-exceeded&quot;&gt;Max result size exceeded&lt;/h3&gt;
&lt;hr /&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt; &lt;span class=&quot;nc&quot;&gt;Typical&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stream5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query_05_22_77&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;Error:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;SparkException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Job&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aborted&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;due&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;failure:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Total&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;serialized&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;381610&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;5.0&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;GB&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bigger&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;than&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;driver&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;maxResultSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;5.0&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;GB&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;code&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;§ &lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Likely&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;occur&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;complex&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;SQL&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;large&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;큰 데이터 볼륨을 처리하기 위한 복잡한 SQL에서 발생할 가능성이 있다.&lt;br /&gt;
Spark Driver Max Result Size값보다 return된 result가 클 때 발생한다.&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--conf spark.driver.maxResultSize&lt;/code&gt; 재설정을 통해 해결한다.&lt;/p&gt;

&lt;h3 id=&quot;too-large-frame-error&quot;&gt;Too Large Frame error&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;shuffle data size block의 size가 스파크가 처리 할 수 있는 한계인 2GB보다 큰 경우 발생.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;org.apache.spark.shuffle.FetchFailedException: Too large frame: XXXXXXXXXX
at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:513)
at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:444)

Caused by: java.lang.IllegalArgumentException: Too large frame: XXXXXXXXXX
at org.spark_project.guava.base.Preconditions.checkArgument(Preconditions.java:119)
at org.apache.spark.network.util.TransportFrameDecoder.decodeNext(TransportFrameDecoder.java:133)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.shuffle.partitions&lt;/code&gt;의 value를 default 200에서 큰 값으로 조정 -&amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.default.parallelism&lt;/code&gt; 을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.sql.shuffle.partitions&lt;/code&gt;과 동일한 값으로 변경&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;issue가 발생하는 dataframe을 밝혀내보자. dataframe 생성 뒤에 action(어떤 action이든, count 등)을 붙여서 dataframe별로 action을 시켜보고, 문제가 생기는 데이터프레임을 밝혀내볼 수 있다. 해당 데이터프레임을 repartition하고 cache해놓는다. 이 때 파티션이 된 데이터의 skewness가 심하다면 코드의 튜닝이 필요할 수 있다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;network-timeout&quot;&gt;Network Timeout&lt;/h3&gt;
&lt;hr /&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;07&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;09&lt;/span&gt; &lt;span class=&quot;mo&quot;&gt;01&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;ERROR&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ContextCleaner&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Error&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cleaning&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;broadcast&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28267&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;rpc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;RpcTimeoutException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Futures&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timed&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;after&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;].&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;This&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeout&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;controlled&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;rpc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;askTimeout&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;rpc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;RpcTimeout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$apache$spark$rpc$RpcTimeout&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;$createRpcTimeoutException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;RpcTimeout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;48&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;rpc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;RpcTimeout&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$anonfun$addMessageIfTimeout&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;applyOrElse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;RpcTimeout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;63&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;rpc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;RpcTimeout&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$anonfun$addMessageIfTimeout&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;applyOrElse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;RpcTimeout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;59&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;PartialFunction&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$OrElse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PartialFunction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;167&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;rpc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;RpcTimeout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;awaitResult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;RpcTimeout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;83&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;BlockManagerMaster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;removeBroadcast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;BlockManagerMaster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;143&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;And&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeout&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exceptions&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;related&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;following:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;core&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ack&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;timeout&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;akka&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;timeout&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;storage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;blockManagerSlaveTimeoutMs&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;connectionTimeout&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;rpc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;askTimeout&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;rpc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;lookupTimeout&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;시스템 리소스 상황에 따라 발생할 수 있다. 시스템 리소스의 튜닝이 최우선이고, 안전장치로 timeout setting을 늘려줄 수 있다.&lt;br /&gt;
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.network.timeout&lt;/code&gt; 파라미터를 늘려준다. default는 120이다. 에러가 발생한 timeout 시간만큼 늘려줘 본다.&lt;/p&gt;

&lt;h3 id=&quot;spark-job-fails-with-throttling-in-s3-when-using-mfoc-aws&quot;&gt;Spark job fails with throttling in S3 when using MFOC (AWS)&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;무겁고 높은 로드를 일으키는 job에서, Multipart Upload를 활성화한 upload가 실패할 수 있다.&lt;/p&gt;

&lt;p&gt;Spark Override configuration에 아래와 같은 설정들을 잡아준다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;해당 작업이 실패할 때, 하둡이 다른 pending된 upload까지 다 abort 시킬 수 있다. 이는 연관된 다른 작업들까지 실패될 수 있으므로, 
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.hadoop.fs.s3a.committer.staging.abort.pending.uploads&lt;/code&gt; 설정을 false로 잡아준다. 이후에 Bucket Lifecycle Policy를 통해 실패된 Multipart Uploaded file을 expire시킬 수 있다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.hadoop.fs.s3a.committer.threads&lt;/code&gt;의 default 값은 8인데, thread의 수를 더 줄여준다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.hadoop.fs.s3a.committer.threads.max&lt;/code&gt; 값을 위의 thread 수와 맞춰준다.
(일반적으로 위의 thread 수를 늘려서 s3 loading 작업을 더 빠르게 만들 수 있지만, S3에서 너무 높은 로드로 실패하는 경우가 생긴다면 이를 줄여서 작게 설정해볼 수 있다.)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;spark.hadoop.fs.s3a.connection.timeout&lt;/code&gt;값을 default 200000 ms에서 더 높은 값으로 잡아줄 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;http-503-slow-down-amazons3exception-aws&quot;&gt;HTTP 503 “Slow Down” AmazonS3Exception (AWS)&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;S3에 스파크로 많은 양의 데이터를 쓰려고 시도하다보면 가끔식 마주치게 되는 에러인 듯 하다.
위의 에러와 같이 엄밀히 말하면 Spark 자체의 에러는 아니지만 S3를 데이터 저장소르 쓰는 경우 스파크로 데이트를 쓰거나 읽을때 발생할 수 있다. prefix마다 초당 3,500개의 PUT/COPY/POST/DELETE 및 5,500개의 GET/HEAD 요청을 넘어갈 때 발생한다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;java.io.IOException: com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Slow Down (Service: Amazon S3; Status Code: 503; Error Code: 503 Slow Down; Request ID: 2E8B8866BFF00645; S3 Extended Request ID: oGSeRdT4xSKtyZAcUe53LgUf1+I18dNXpL2+qZhFWhuciNOYpxX81bpFiTw2gum43GcOHR+UlJE=), S3 Extended Request ID: oGSeRdT4xSKtyZAcUe53LgUf1+I18dNXpL2+qZhFWhuciNOYpxX81bpFiTw2gum43GcOHR+UlJE=

&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ol&gt;
  &lt;li&gt;가장 기본적인 해결법으로 버킷의 prefix를 더 나누는 방법이 있다.
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;s3://awsexamplebucket/images
s3://awsexamplebucket/videos
s3://awsexamplebucket/documents
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;그러면 prefix 3개로 나뉘어져서 해당 버킷에 대해 초당 10,500건의 쓰기 요청 또는 16,500건의 읽기 요청을 할 수 있다. &lt;br /&gt;
이 때 prefix란 bucket + 1 depth까지의 namespace까지를 말한다. 즉 s3://awsexamplebucket/images/prefix_depth2, s3://awsexamplebucket/images/prefix_depth3 으로 2 depth 이하로 prefix를 나누는 경우는 이 로직이 동작하지 않는다. 우리 시스템 같은 경우 이렇게 여러 depth를 들어간 이후 table구조를 구성하고 있기 때문에 한 때 이 에러를 자주 마주쳤다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Amazon S3 요청 수 줄이기&lt;br /&gt;
디렉토리 구조를 통으로 바꾸는 것은 간단한 일이 아니기 때문에 우리는 Spark Job의 병렬도를 낮춰서 해결했다. 
위와 같은 제약사항을 고려하여 S3 bucket 구조를 설계할 때, 한 bucket에 모든 데이터를 담고 그 아래 prefix를 여러 depth로 쪼개는 것보다 목적에 따라 여러 bucket과 1depth의 prefix를 가져가는 구조로 설계하는 것이 좋아보인다.&lt;/li&gt;
  &lt;li&gt;EMRFS 재시도 제한 증가
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;[
 {
   &quot;Classification&quot;: &quot;emrfs-site&quot;,
   &quot;Properties&quot;: {
     &quot;fs.s3.maxRetries&quot;: &quot;20&quot;,
     &quot;fs.s3.consistent.retryPeriodSeconds&quot;: &quot;10&quot;,
     &quot;fs.s3.consistent&quot;: &quot;true&quot;,
     &quot;fs.s3.consistent.retryCount&quot;: &quot;5&quot;,
     &quot;fs.s3.consistent.metadata.tableName&quot;: &quot;EmrFSMetadata&quot;
   }
 }
]
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.qubole.com/en/latest/troubleshooting-guide/spark-ts/troubleshoot-spark.html&quot;&gt;https://docs.qubole.com/en/latest/troubleshooting-guide/spark-ts/troubleshoot-spark.html&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://medium.com/ibm-data-ai/beginners-troubleshooting-guide-for-spark-ibm-analytics-engine-199019cfc6b4&quot;&gt;https://medium.com/ibm-data-ai/beginners-troubleshooting-guide-for-spark-ibm-analytics-engine-199019cfc6b4&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://www.slideshare.net/jcmia1/a-beginners-guide-on-troubleshooting-spark-applications&quot;&gt;https://www.slideshare.net/jcmia1/a-beginners-guide-on-troubleshooting-spark-applications&lt;/a&gt;
&lt;a href=&quot;https://aws.amazon.com/ko/premiumsupport/knowledge-center/emr-s3-503-slow-down/&quot;&gt;https://aws.amazon.com/ko/premiumsupport/knowledge-center/emr-s3-503-slow-down/&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Fri, 30 Apr 2021 01:43:00 +0900</pubDate>
        <link>https://jaemunbro.github.io/posts/troubleshooting-spark/</link>
        <guid isPermaLink="true">https://jaemunbro.github.io/posts/troubleshooting-spark/</guid>
        
        <category>spark</category>
        
        <category>troubleshooting</category>
        
        
        <category>Spark</category>
        
      </item>
    
      <item>
        <title>블로그 이사</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://jaemunbro.medium.com/&quot;&gt;Medium&lt;/a&gt; 외에 github로 블로그를 시작했다.&lt;/p&gt;

&lt;p&gt;Medium 플랫폼은 처음에는 Netflix 등의 기업 테크 블로그 때문에 Medium 플랫폼에 들어가게 되었고 이런 경험들을 통해서 ‘호감’ 플랫폼으로 자리잡게 되었었는데, 점차 몇몇 기업의 테크 블로그를 제외한 일반 블로그들 중에는 clickbait 같은, 흥미로운 제목으로 클릭을 유발하는 유료 자료가 많아지는 느낌이다.&lt;br /&gt;
 특히 구글을 검색해서 미디움 페이지를 클릭했을 때, 몇줄 나오고 유료라서 더 이상 볼 수 없다는 알림을 보는 경험은… 정말 별로다. 굳이 보려면 우회해서 볼 수 있기는 하지만, 이런 포스트들은 차라리 구글 검색에서 제외 되었으면 좋겠다는 생각을 하게 된다.&lt;br /&gt;
 이런 유료 포스터가 계속 늘어난다면 미디움은 헤비 블로거와 유료로 구독하는 일부 유저에게는 좋은 플랫폼일 수도 있지만, 대부분의 일반 라이트 유저들에게는 그닥 좋지 않은 경험을 선사하는 플랫폼이 되어갈 수도 있을 것 같다.&lt;/p&gt;

&lt;p&gt;최근에 reddit을 돌아다니다가 Medium에 대한 &lt;a href=&quot;https://www.reddit.com/r/datascience/comments/mam99b/is_the_subscription_for_towards_data_science/&quot;&gt;‘Is the subscription for Towards Data Science (Medium blog) worth it?
‘&lt;/a&gt;이라는 포스트를 우연히 봤는데, 대세는 ‘그럴만한 가치는 없어보인다’였다. 
 음.. 역시.. 나만 생각하고 있었던 건 아닌가보군.. Towards Data Science는 개인적으로는 정보를 검색하다 괜찮은 정보도 종종 있어서 잘 알고 있는 채널이지만, 유료로 구독해야한다면 글쎄..&lt;br /&gt;
 아무튼 reddit의 글이 트리거가 되어서 새로운 블로그를 해보기로 결심했다.&lt;/p&gt;

&lt;p&gt;그럼 그닥 많지는 않지만 그래도 그동안 써놨던 포스트들은 어쩌지? 옮겨와야 하나? 마크다운으로 바꾸려면 단순 복붙으로는 안되고 노동이 좀 필요한데.. 이건 도저히 못할 것 같다. 생각해보면 사실 그닥 해야될 이유도 없고..ㅎㅎ 두세개 옮겨두고 싶은 글은 할 수도 있지만, 나머지는 나중에 혹 시간이 나면 해야겠다(=안한다).&lt;/p&gt;

</description>
        <pubDate>Tue, 27 Apr 2021 11:25:00 +0900</pubDate>
        <link>https://jaemunbro.github.io/posts/blog-migration/</link>
        <guid isPermaLink="true">https://jaemunbro.github.io/posts/blog-migration/</guid>
        
        <category>thoughts</category>
        
        
        <category>ETC</category>
        
        <category>Thoughts</category>
        
      </item>
    
      <item>
        <title>Features of NoSQL Databases (NoSQL 데이터베이스별 특징)</title>
        <description>&lt;p&gt;초기의 파일 기반이나 계층형 데이터베이스 이후 수십년동안 데이터베이스가 곧 관계형 데이터베이스로 이해될 만큼 관계형 데이터베이스 중심의 시장이 지속되어 왔다. 그러나 최근 몇 년간 대용량 데이터에 대한 요구가 급격히 커지면서 대용량 데이터의 처리에 강점을 가진 NoSQL과 같은 다양한 데이터베이스 모델이 개발되었다.&lt;/p&gt;

&lt;p&gt;관계형 데이터베이스와 NoSQL 데이터베이스의 특징과 차이에 대해 간단히 정리해보자.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;관계형 데이터베이스는 엔터티의 구조와 엔터티 간의 관계를 토대로 설계하지만, NoSQL에서는 일반적으로 엔터티 관계 구조를 갖지 않는다.&lt;/li&gt;
  &lt;li&gt;관계형 모델은 데이터 간의 관계를 정의하고 데이터 정합성, 일관성을 유지하기 위한 모델로서 출현했다.
NoSQL은 대용량 데이터의 읽기와 쓰기 작업을 위해 기존 관계형 데이터베이스 구조로는 부족한 점에 대한 대안으로서 출현했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;nosql의-일반적인-장단점&quot;&gt;NoSQL의 일반적인 장단점&lt;/h3&gt;
&lt;hr /&gt;
&lt;ul&gt;
  &lt;li&gt;장점
    &lt;ul&gt;
      &lt;li&gt;NoSQL은 대용량 데이터의 읽기와 쓰기에 강점을 가진다. (수평적 확장이 용이하다)&lt;/li&gt;
      &lt;li&gt;관계형 데이터베이스에서 명확하게 정의된 스키마를 강제함을 통해 데이터 무결성을 보장한다면, NoSQL에서는 유연하게 스키마를 정의할 수 있다. 이러한 장점을 활용해서 document DB등에서 스키마 디자인등에 구애받지 않는 빠른 테스트를 진행해볼 수도 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;단점
    &lt;ul&gt;
      &lt;li&gt;대용량 데이터의 읽기와 쓰기에 대한 trade-off로, 관계형 데이터의 주요한 특성인 즉각적인 일관성(consistency)을 만족시키지 못하는 경우가 많다.  일반적으로 최종적인 일관성(Eventually consistent)을 지원한다.&lt;/li&gt;
      &lt;li&gt;ACID 트랜잭션을 지원하지 않을 수 있다.&lt;/li&gt;
      &lt;li&gt;스키마를 강제하지 않으므로 그 정의가 유연하고 편리한 대신, 개발자가 애플리케이션 레벨에서 데이터에 대한 무결성 검증을 직접 해야만 한다.&lt;/li&gt;
      &lt;li&gt;보편적인 SQL 문법을 지원하지 않는 경우가 많으므로 이에 대한 Learning Curve가 상대적으로 큰 편이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;cap-theorem&quot;&gt;CAP Theorem&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;CAP 정리는 NoSQL에 대해 처음에 이해하기 위해 가장 많이 언급되는 이론이다.&lt;br /&gt;
하지만 CAP 정리는 하나의 일관성 모델과 한 종류의 결함(네트워크 분단)만 고려하므로 실제 시스템에서 고려해야 하는 네트워크 지연, 죽은 노드나 다른 트레이드오프들에 대해서 고려하지 않는다는 한계가 있다. 따라서 CAP 정리는 초기에 NoSQL 컨셉에 대한 이해를 돕기 위한 목적 외에 실제 시스템을 설계할 때 쓰기 위한 실용적인 가치는 크지 않다는 점을 알아두자.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Consistency(일관성) : 모든 노드들은 같은 시간에 동일한 항목에 대하여 같은 내용의 데이터를 사용자에게 보여준다.&lt;/li&gt;
  &lt;li&gt;Availability(가용성) : 모든 사용자들이 읽기 및 쓰기가 가능해야 하며, 몇몇 노도의 장애 시에도 다른 노드에 영향을 미치지 않는다.&lt;/li&gt;
  &lt;li&gt;Partition Tolerance(분할내성) : 메시지 전달이 실패하거나 시스템 일부가 망가져도 시스템이 계속 동작할 수 있어야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/117692092-a0ef2e00-b1f7-11eb-8846-2828f79b87c5.png&quot; alt=&quot;image&quot; /&gt;&lt;em&gt;Database Systems according to the CAP theorem, from https://www.researchgate.net/&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;위의 조건에서 P를 기본조건으로 두고, Consistency와 Availability가 충돌하는 상황의 예시를 보자.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;CP&lt;/strong&gt; : 애플리케이션에서 일관성을 요구하는 상황에서 일부 복제 서버가 네트워크 문제로 다른 서버와 연결이 끊기면 그동안은 연결을 처리할 수 없다. 네트워크 문제가 고쳐질 때까지 기다리거나 오류를 반환해야한다. 어떻게 해도 가용성(Availability)이 보장되지 않는다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;AP&lt;/strong&gt; : 애플리케이션에서 일관성을 요구하지 않는다면, 각 복제 서버가 연결이 끊기더라도 독립적으로 요청을 처리하는 식으로 가용성(Availability)을 제공할 수 있다. 단 일관성은 깨어진 상태일 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;nosql-데이터베이스별-특성&quot;&gt;NoSQL 데이터베이스별 특성&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;NoSQL 데이터베이스를 세분화해서 Key-Value, Document등 각 NoSQL 데이터베이스별 특성을 알아보고, 우리 애플리케이션에 맞는 데이터베이스는 무엇일지 고민해보았다.&lt;/p&gt;

&lt;p&gt;NoSQL 데이터베이스의 특성을 크게 네가지로 나누면 다음과 같이 나눌 수 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Key-Value Database&lt;/li&gt;
  &lt;li&gt;Document Database&lt;/li&gt;
  &lt;li&gt;Column Family Database&lt;/li&gt;
  &lt;li&gt;Graph Database&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;본문에서 Graph Database를 제외한 나머지 세개의 데이터베이스의 특성에 대해 간단히 정리하고 어떤 상황에 어떤 데이터베이스가 적합할지 알아보고자 한다.&lt;/p&gt;

&lt;h1 id=&quot;key-value-database&quot;&gt;Key-Value Database&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;키와 값으로 이루어진, 저장과 조회라는 가장 간단한 원칙에 충실한 데이터베이스. 더 넓은 의미로 Key-Value Database를 사용하는 경우 Column Family Database들도 포함하여 이야기하는 경우도 많다. 본문에서는 조금 더 세분화해서 그 둘을 구분해서 분류하였다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key-Value Database의 Key 값은 unique한 고유값&lt;/strong&gt;으로 유지되어야 한다.&lt;br /&gt;
&lt;strong&gt;테이블간 조인을 고려하지 않으므로 RDB(Relational Database)에서 관리하는 외부키나, 컬럼별 constraints등이 필요 없다.&lt;/strong&gt; 값에 모든 데이터 타입을 허용하며, 그래서 개발자들이 데이터 입력 단계에서 &lt;strong&gt;애플리케이션 레벨에 검증 로직&lt;/strong&gt;을 제대로 구현하는 것이 중요하다.(schema-on-read)&lt;br /&gt;
Key-Value Database는, 간단한 데이터 모델을 대상으로 데이터를 자주 읽고 쓰는 애플리케이션에 적합하다. 값은 boolean이나 integer값처럼 단순한 스칼라 값이 일반적이지만, 리스트나 JSON같은 구조화된 값도 가능하다.&lt;/p&gt;

&lt;h3 id=&quot;key-value-databases&quot;&gt;Key-Value Databases&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Redis&lt;/li&gt;
  &lt;li&gt;Riak&lt;/li&gt;
  &lt;li&gt;Oracle Berkely&lt;/li&gt;
  &lt;li&gt;AWS DynamoDB&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;key-value-database는-주로-아래와-같은-형태의-애플리케이션에서-사용된다&quot;&gt;Key-Value Database는 주로 아래와 같은 형태의 애플리케이션에서 사용된다.&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;성능 향상을 위해 관계형 데이터베이스에서 데이터 캐싱&lt;/li&gt;
  &lt;li&gt;장바구니 같은 웹 애플리케이션에서 일시적인 속성 추적&lt;/li&gt;
  &lt;li&gt;모바일 애플리케이션용 사용자 데이터 정보와 구성 정보 저장&lt;/li&gt;
  &lt;li&gt;이미지나 오디오 파일 같은 대용량 객체 저장&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;document-database&quot;&gt;Document Database&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;Document Database 또는 Document-Oriented Database는 위의 Key-Value Database와 같이 데이터 저장에 Key-Value Type를 사용한다.&lt;br /&gt;
하지만 Key-Value Database와의 중요한 차이는 &lt;strong&gt;Document Database는 값을 문서로 저장&lt;/strong&gt;한다는 점이다. 여기서 문서란 &lt;strong&gt;semi-structured entity이며 보통 JSON이나 XML 같은 표준 형식&lt;/strong&gt;을 말한다.&lt;br /&gt;
값을 저장하기 전에 schema를 별도로 정의하지 않으며, 문서를 추가하면 그게 바로 schema가 된다.&lt;br /&gt;
각 문서별로 다른 필드를 가질 수 있으며, 따라서 이 역시 &lt;strong&gt;개발자가 애플리케이션에서 데이터를 입력하는 단계에서 컬럼과 필드의 관리가 제대로 이루어지도록 보장&lt;/strong&gt;하는 것이 매우 중요하다. 예를 들어 필수 속성(Null을 허용하지 않는 속성)에 대한 관리도 애플리케이션 레벨에서 관리가 이루어져야 한다.&lt;/p&gt;

&lt;p&gt;예시로 MongoDB의 AirBnB DataSet의 일부를 보자. 다음과 같은 JSON 형태의 문서로 관리된다.&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;10006546&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;listing_url&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://www.airbnb.com/rooms/10006546&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Ribeira Charming Duplex&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;summary&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Fantastic duplex apartment with three bedrooms, located in the historic area of Porto, Ribeira (Cube)...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;house_rules&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Make the house your home...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;property_type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;House&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;calendar_last_scraped&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;$date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
       &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;$numberLong&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1550293200000&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;amenities&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;TV&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Cable TV&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Wifi&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Kitchen&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Paid parking off premises&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Smoking allowed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Microwave&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;document-databases&quot;&gt;Document Databases&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;MongoDB&lt;/li&gt;
  &lt;li&gt;CouchDB&lt;/li&gt;
  &lt;li&gt;Couchbase&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;document-database는-다음과-같은-목적으로-주로-활용된다&quot;&gt;Document Database는 다음과 같은 목적으로 주로 활용된다.&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;대용량 데이터를 읽고 쓰는 웹 사이트용 백엔드 지원&lt;/li&gt;
  &lt;li&gt;제품처럼 다양한 속성이 있는 데이터 관리&lt;/li&gt;
  &lt;li&gt;다양한 유형의 메타데이터 추적&lt;/li&gt;
  &lt;li&gt;JSON 데이터 구조를 사용하는 애플리케이션&lt;/li&gt;
  &lt;li&gt;비정규화된 중첩 구조의 데이터를 사용하는 애플리케이션&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;column-family-database&quot;&gt;Column Family Database&lt;/h1&gt;
&lt;hr /&gt;
&lt;p&gt;컬럼 패밀리 데이터베이스는 대용량 데이터, 읽기와 쓰기 성능, 고가용성을 위해 설계되었다. 구글에서 Big Table을 도입하고, 페이스북은 Cassandra를 개발했다.&lt;/p&gt;

&lt;p&gt;Column과 Row와 같이 Relation Database와 동일한 용어를 사용하여 스키마를 정의한다.&lt;br /&gt;
컬럼 수가 많다면 관련된 컬럼들을 컬렉션으로 묶을 수 있다. 예를 들어 이름의 성과 이름을 하나로 묶고, 사무실, 핸드폰 등의 전화번호들을 하나로 묶을 수 있다. 이렇게 묶인 컬럼들을 &lt;strong&gt;Column Family&lt;/strong&gt;라고 한다.&lt;/p&gt;

&lt;p&gt;Document Database와 마찬가지로 미리 정의된 스키마를 사용하지 않으므로 개발자가 데이터를 입력하는 시점에 원하는대로 컬럼을 추가할 수 있다.&lt;br /&gt;
테이블간 조인을 지원하지 않는다.&lt;br /&gt;
관계형 데이터베이스에서 한 객체에 대한 정보를 저장하기 위해 여러 테이블에 나누어 저장한다. 예를 들면 고객의 기본 정보 테이블(이름, 주소, 연락처)와 고객의 주문 정보 테이블 등을 나누어서 저장하고 조인을 통해 이객체의 정보를 활용한다.&lt;br /&gt;
컬럼패밀리 데이터베이스는 일반적으로 &lt;strong&gt;비정규화 되어 있으며 한 객체에 관련된 모든 정보를 가능한 매우 너비가 넓은 단일 Row에 넣어서 보관&lt;/strong&gt;한다. 따라서 한 Row에 수백만개의 컬럼을 보관하는 경우도 비정상적인 것은 아니다.&lt;br /&gt;
컬럼 패밀리 데이터베이스는 여러대로 구성된 클러스터에서 운영된다. 단일 서버에서 운영해도 될만큼 데이터가 적다면 문서나 키-값 데이터베이스를 고려하는 것이 나을 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/117672530-e6563000-b1e4-11eb-96f2-9363b51c2ab4.png&quot; alt=&quot;image&quot; title=&quot;Hbase의 Column Families(from https://www.tutorialspoint.com/hbase/hbase_create_data.html)&quot; /&gt;&lt;em&gt;Hbase의 Column Families(from tutorialspoint&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;column-family-databases&quot;&gt;Column Family Databases&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Hbase&lt;/li&gt;
  &lt;li&gt;Cassandra&lt;/li&gt;
  &lt;li&gt;GCP BigTable&lt;/li&gt;
  &lt;li&gt;Microsoft Azure Cosmos DB&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;column-family-database는-다음과-같은-경우에-활용을-고려하면-좋다&quot;&gt;Column Family Database는 다음과 같은 경우에 활용을 고려하면 좋다.&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;데이터베이스에 쓰기 작업이 많은 애플리케이션&lt;/li&gt;
  &lt;li&gt;지리적으로 여러 데이터 센터에 분산되어 있는 애플리케이션&lt;/li&gt;
  &lt;li&gt;복제본 데이터가 단기적으로 불일치하더라도 큰 문제가 없는 애플리케이션&lt;/li&gt;
  &lt;li&gt;동적 필드를 처리하는 애플리케이션&lt;/li&gt;
  &lt;li&gt;수백만 테라바이트 정도의 대용량 데이터를 처리할 수 있는 애플리케이션&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;hbase-vs-cassandra&quot;&gt;HBase vs Cassandra&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;Column Family Database의 대표격인 Hbase와 Cassandra를 비교해보자.&lt;br /&gt;
두 데이터베이스 중 더 보편적으로 활용되는 것은 Cassandra이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/117672932-464cd680-b1e5-11eb-9e7c-dcec38066f8d.png&quot; alt=&quot;image&quot; title=&quot;Column Family Database(A.K.A Wide Column Stores)의 트렌드 차트(DB-Engines.com)&quot; /&gt;&lt;em&gt;Column Family Database(A.K.A Wide Column Stores)의 트렌드 차트(DB-Engines.com)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;아래는 Hbase와 Cassandra간의 Benchmark 테스트 자료(2017)가 있어 첨부하였다.&lt;br /&gt;
high-io가 일어나는 프로덕션 환경을 가정하여 SSD 기반의 머신 5대에서 수행하였다. 벤치마크에 사용된 것은 YCSB(Yahoo! Cloud Serving Benchmark) 툴이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/117673071-68465900-b1e5-11eb-8fb1-18013019e2f3.png&quot; alt=&quot;image&quot; title=&quot;hbase와 cassandra benchmark test&quot; /&gt;&lt;em&gt;(hbase와 cassandra benchmark test from https://blog.cloudera.com/hbase-cassandra-benchmark/)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;위의 벤치마크 테스트 결과를 보면 Hbase가 대부분의 heavy한 read 작업에서 Cassandra보다 더 나은 성능을 보이고 있다. HBase의 주요한 사용 사례인 search engine이나 high-frequency transaction 애플리케이션, 대용량 로그 분석에 잘 들어맞는 결과이다. 반면에 Cassandra는 write-heavy한 작업에서 데이터일관성을 유지하며 좋은 결과를 보였다. 따라서 빠른 수행 시간보다 분석 데이터 수집이나 센서 데이터 수집 등 일관성 있는 데이터의 수집이 더 중요한 경우에 적절한 대안이 될 수 있을 것이다.&lt;/p&gt;

&lt;p&gt;위와 같이 전반적으로 Hbase가 Cassandra보다 일반적으로 더 나은 성능을 보임에도 불구하고 Cassandra가 더 보편적으로 선호되는 이유는 무엇일까?&lt;br /&gt;
이는 시스템 복잡도나 Learning Curve가 HBase가 더 높기 때문으로 보인다.&lt;br /&gt;
Hbase 자체로는 SQL-Like Language를 제공하지 않아 JRuby 베이스의 HBase shell을 활용해서 쿼리해야 한다. 이 때문에 일단 SQL 대비 Learning curve가 있는 편이다. 혹은 Apache Phoenix라는 쿼리를 위한 별도의 솔루션을 추가로 구성해야한다. 혹은 기존Spark나 Hive와 같은 커넥터를 활용할 수 있는데, 이러한 커넥터를 활용하는 DFS경우 상대적으로 high latency가 발생하게 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/117673308-a6437d00-b1e5-11eb-9423-c1a7edc6ec19.png&quot; alt=&quot;image&quot; /&gt;&lt;em&gt;(Hive와 Phoenix를 활용한 Hbase 쿼리 성능 from https://phoenix.apache.org/performance.html)&lt;/em&gt;
클러스터 구축면에서도 HBase가 더 난이도가 높은 편이다. Hadoop Cluster의 Data nodes에 구성하므로 스케일링은 편리하지만, 최소 5대의 데이터 노드와 하나의 네임노드를 필요로 하는 만큼 최소 유지비용이 많이 드는 편이다.&lt;br /&gt;
또한 HBase는 단독 클러스터 구성이 불가하며 HDFS를 스토리지로 활용하고 Apache Zookeeper를 status 관리와 metadata에 활용하므로, 이러한 기술에 익숙치 않다면 환경 설정이 상대적으로 어려울 수 있다.&lt;br /&gt;
이렇게 HBase 환경을 구축하고 원활하게 운영하기 위해서는 Cassandra 대비 좀 더 난이도 있는 엔지니어링 리소스와 Learning curve를 필요로 하기 때문에 Cassandra가 더 보편적으로 활용되는 것으로 보인다.&lt;/p&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;
&lt;p&gt;Dan Sullivan, Perfect Introduction to NoSQL(NoSQL 철저입문), 2015, 길벗&lt;br /&gt;
&lt;a href=&quot;https://blog.cloudera.com/hbase-cassandra-benchmark/&quot;&gt;https://blog.cloudera.com/hbase-cassandra-benchmark/&lt;/a&gt;
&lt;a href=&quot;https://logz.io/blog/nosql-database-comparison/&quot;&gt;Cassandra vs. MongoDB vs. Hbase: A Comparison of NoSQL Databases&lt;/a&gt;
&lt;a href=&quot;https://www.kdnuggets.com/2018/08/dynamodb-vs-cassandra.html&quot;&gt;DynamoDB vs. Cassandra: from “no idea” to “it’s a no-brainer” - KDnuggets&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Sat, 06 Feb 2021 00:00:00 +0900</pubDate>
        <link>https://jaemunbro.github.io/posts/nosql-databases/</link>
        <guid isPermaLink="true">https://jaemunbro.github.io/posts/nosql-databases/</guid>
        
        <category>nosql</category>
        
        
        <category>NoSQL</category>
        
      </item>
    
      <item>
        <title>Spark - Config Executors (스파크 - 최적의 익스큐터 사이즈와 개수 정하기)</title>
        <description>&lt;p&gt;&lt;em&gt;Original Post: &lt;a href=&quot;https://jaemunbro.medium.com/spark-executor-%EA%B0%9C%EC%88%98-%EC%A0%95%ED%95%98%EA%B8%B0-b9f0e0cc1fd8&quot;&gt;[Apache Spark] Executor 사이즈와 개수 정하기&lt;/a&gt; 에서 옮겨왔습니다.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Spark Application을 띄울때 가장 기본적으로 설정해야하는 요소.&lt;br /&gt;
Executor의 사이즈와 개수는 어떻게 정하는 것이 좋을까?&lt;/p&gt;

&lt;p&gt;Executor에 관한 몇 가지 기본 전제를 먼저 확인해보자.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;executor는 캐싱과 실행을 위한 공간을 갖고 있는 JVM이다.&lt;/li&gt;
  &lt;li&gt;executor와 driver의 사이즈는 하나의 노드나 컨테이너에 할당된 자원보다 많은 메모리나 코어를 가질 수 없다.&lt;/li&gt;
  &lt;li&gt;executor의 일부 공간은 스파크의 내부 메타 데이터와 사용자 자료구조를 위해 예약되어야 한다. (평균 약 25%) 이 공간은 spark.memory.fraction 설정으로 변경 가능하며 기본값은 0.6으로, 60%의 공간이 저장과 실행에 쓰이고 40%는 캐싱에 쓰인다.&lt;/li&gt;
  &lt;li&gt;하나의 partition이 여러개 executor에서 처리될 수 없다 :&lt;br /&gt;
하나의 partition은 하나의 executor에서 처리.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;다수의-작은-executor-vs-소수의-큰-executor&quot;&gt;다수의 작은 executor VS. 소수의 큰 executor?&lt;/h1&gt;
&lt;h2 id=&quot;다수의-작은-executor의-문제&quot;&gt;다수의 작은 executor의 문제&lt;/h2&gt;
&lt;hr /&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;하나의 파티션을 처리할 자원이 충분하지 않을 수도 있다.&lt;/strong&gt;&lt;br /&gt;
하나의 파티션이 여러개의 executor에서 계산될 수는 없다. 따라서 셔플, skewed 데이터의 캐시, 복잡한 연산의 transformation 수행 시 OOME 또는 disk spill이 생길 수 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;자원의 효율적 사용이 힘들다.&lt;/strong&gt;&lt;br /&gt;
같은 노드내 executor끼리 통신에도 약간의 비용이 필요하다.
1GB executor를 갖고 있는 경우 연산을 제외한 오버헤드에만 250MB, 거의 25% 수준의 공간을 써야할 수도 있다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;따라서 &lt;strong&gt;자원이 허용된다면, executor는 최소 4GB 이상&lt;/strong&gt;으로 설정하는 것을 추천한다.&lt;/p&gt;

&lt;h2 id=&quot;소수의-큰-executor의-문제&quot;&gt;소수의 큰 executor의 문제&lt;/h2&gt;
&lt;hr /&gt;
&lt;ol&gt;
  &lt;li&gt;너무 큰 executor는 힙 사이즈가 클 수록 GC가 시작되는 시점을 지연시켜 &lt;strong&gt;Full GC로 인한 지연&lt;/strong&gt;이 더욱 길어질 수 있다.&lt;/li&gt;
  &lt;li&gt;executor당 많은 수의 코어를 쓰면 동시 스레드가 많아지면서 스레드를 다루는 HDFS의 제한으로 인해 성능이 더 떨어질 수도 있다.
Sandy Ryza(&lt;a href=&quot;https://www.amazon.com/Advanced-Analytics-Spark-Patterns-Learning-ebook/dp/B072KFWZ8S&quot;&gt;Advanced Analytics with Spark&lt;/a&gt;의 저자)는 &lt;strong&gt;executor당 5개의 코어를 최대&lt;/strong&gt;로 보아야 한다고 제안한다.(&lt;a href=&quot;https://blog.cloudera.com/how-to-tune-your-apache-spark-jobs-part-2/&quot;&gt;https://blog.cloudera.com/how-to-tune-your-apache-spark-jobs-part-2/&lt;/a&gt;)&lt;br /&gt;
경험적으로 볼 때, 7–8개 이상의 코어 할당은 성능 향상에 도움도 되지 않을 뿐더러 CPU 자원을 불필요하게 소모하게 한다고 한다.
(&lt;strong&gt;Yarn에서 활용하는 경우 64GB 정도를 upper limit&lt;/strong&gt;으로 보면 좋다.)&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;효율적-세팅을-위해서&quot;&gt;효율적 세팅을 위해서&lt;/h1&gt;
&lt;p&gt;CPU 자원 기준으로 executor의 개수를 정하고,&lt;br /&gt;
&lt;strong&gt;executor 당 메모리는 4GB 이상, executor당 core 개수( 1 &amp;lt; number of CPUs ≤ 5)&lt;/strong&gt; 기준으로 설정한다면 일반적으로 적용될 수 있는 효율적인 세팅이라고 할 수 있겠다.&lt;br /&gt;
core와 memory size 세팅의 starting point로는 아래 설정을 잡으면 무난할 듯 하다.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;—-executor-cores 2 --executor-memory 16GB
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;예를-들어보면&quot;&gt;예를 들어보면&lt;/h1&gt;
&lt;p&gt;AWS EMR에 m5.2xlarge를 master로, m5.24xlarge를 core로 10대 띄운 상황을 예시로 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/117181500-44170080-ae10-11eb-954b-9350ea1cdb24.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;EMR 서버 현황
    &lt;ul&gt;
      &lt;li&gt;Core 서버 : m5.24xlarge 10대&lt;/li&gt;
      &lt;li&gt;서버당 vCore : 96개&lt;/li&gt;
      &lt;li&gt;서버당 Memory : 384GiB&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;서버당 executor 수
executor 당 core 수를 먼저 정의하고, 이를 통해 vCore에서 활용할 수 있는 전체 executor 수가 정의될 수 있다.&lt;br /&gt;
executor당 core 수 4개로 지정 시 : 96 vcore / 4 = 24개&lt;br /&gt;
그러나 &lt;strong&gt;Hadoop과 Application Master가 사용할 core등도 제외해야하므로, Yarn의 모든 리소스를 100% 쓸 수는 없다.&lt;/strong&gt; 그래서 노드당 &lt;strong&gt;executor는 23개(23*4 = 92 core)&lt;/strong&gt;로 정의했다 : 최종 23 * 10 nodes = 230
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;—-executor-cores 4 --num-executors 230
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;executor당 memory
(Yarn의 resource 가용 memory는 OS와 hadoop deamon 등의 사용분을 제외해야 함. 여기서는 계산을 위해 임의로 노드당 360GB로 가정)
&lt;strong&gt;: 360GB / 24 = 15G&lt;/strong&gt;
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;—-executor-cores 4 --num-executors 230 --executor-memory 15GB
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(참고) m5.xlarge (4core/16GiB memory)를 core로 2대 띄운 EMR 클러스터 전체의 가용 메모리는 24GB으로 전체의 70% 정도   (yarn.scheduler.maximum-allocation-mb 설정값)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/29077671/117181528-4b3e0e80-ae10-11eb-90ad-ed07189180f5.png&quot; alt=&quot;image&quot; title=&quot;리소스 매니저&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;더-알아보기-좋은-자료&quot;&gt;더 알아보기 좋은 자료&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;[Apache Spark] &lt;a href=&quot;https://medium.com/@jaemunbro/apache-spark-partition-%EA%B0%9C%EC%88%98%EC%99%80-%ED%81%AC%EA%B8%B0-%EC%A0%95%ED%95%98%EA%B8%B0-3a790bd4675d&quot;&gt;Partition 개수와 크기 정하기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/blogs/big-data/best-practices-for-successfully-managing-memory-for-apache-spark-applications-on-amazon-emr/&quot;&gt;Best practices for successfully managing memory for Apache Spark applications on Amazon EMR&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;
&lt;p&gt;Holden Karau, High Performance Spark, JPub, pp.303, 2017&lt;br /&gt;
&lt;a href=&quot;https://blog.cloudera.com/how-to-tune-your-apache-spark-jobs-part-2/&quot;&gt;https://blog.cloudera.com/how-to-tune-your-apache-spark-jobs-part-2/&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://blog.cloudera.com/how-does-apache-spark-3-0-increase-the-performance-of-your-sql-workloads/&quot;&gt;https://blog.cloudera.com/how-does-apache-spark-3-0-increase-the-performance-of-your-sql-workloads/&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 30 Apr 2020 00:00:00 +0900</pubDate>
        <link>https://jaemunbro.github.io/posts/spark-config-executors/</link>
        <guid isPermaLink="true">https://jaemunbro.github.io/posts/spark-config-executors/</guid>
        
        <category>spark</category>
        
        <category>executor</category>
        
        
        <category>Spark</category>
        
      </item>
    
  </channel>
</rss>
